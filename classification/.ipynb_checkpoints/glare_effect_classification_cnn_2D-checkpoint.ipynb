{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling2D, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_splits(base_path='C:\\\\Users\\\\dylin\\\\Documents\\\\BA_Glare_Effect\\\\classification_data_initial\\\\features\\\\', splits=20):\n",
    "    real_data_splits_train = []\n",
    "    real_data_splits_test = []\n",
    "    simulated_data_splits_train = []\n",
    "    for split in range(1, splits + 1):\n",
    "        # Real data for training\n",
    "        X_realData_train = np.load(base_path + 'real\\\\Split%s\\\\for_simulation\\\\X_realData_train.npy' %str(split))\n",
    "        y_realData_train = np.load(base_path + 'real\\\\Split%s\\\\for_simulation\\\\y_realData_train.npy' %str(split))\n",
    "        real_data_splits_train.append((X_realData_train, y_realData_train))\n",
    "        \n",
    "        # Real data for testing\n",
    "        X_realData_test = np.load(base_path + 'real\\\\Split%s\\\\for_testing\\\\X_realData_test.npy' %str(split))\n",
    "        y_realData_test = np.load(base_path + 'real\\\\Split%s\\\\for_testing\\\\y_realData_test.npy' %str(split))\n",
    "        real_data_splits_test.append((X_realData_test, y_realData_test))\n",
    "    \n",
    "        # Simulated data for training\n",
    "        X_simulatedData_train = np.load(base_path + 'simulated\\\\Split%s\\\\X_simulatedData_train.npy' %str(split))\n",
    "        y_simulatedData_train = np.load(base_path + 'simulated\\\\Split%s\\\\y_simulatedData_train.npy' %str(split))\n",
    "        simulated_data_splits_train.append((X_simulatedData_train, y_simulatedData_train))\n",
    "    return real_data_splits_train, real_data_splits_test, simulated_data_splits_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_train, real_data_splits_test, simulated_data_splits_train = load_data_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "       [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "       [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "       [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "       [ 2.2, 14. ,  9. ,  1. ,  0. ],\n",
       "       [ 2.1, 12. ,  9. ,  2. ,  0. ],\n",
       "       [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "       [ 6.1, 12. ,  7. ,  2. ,  0. ],\n",
       "       [ 5.2, 12. ,  6. ,  2. ,  0. ],\n",
       "       [ 5.1, 10. ,  6. ,  2. ,  0. ],\n",
       "       [ 3.2, 10. ,  5. ,  2. ,  0. ],\n",
       "       [ 3.1,  8. ,  5. ,  2. ,  0. ],\n",
       "       [ 7.1,  8. ,  4. ,  2. ,  0. ],\n",
       "       [ 6.1,  8. ,  4. ,  2. ,  0. ],\n",
       "       [ 1.2,  8. ,  3. ,  2. ,  0. ],\n",
       "       [ 1.1,  6. ,  3. ,  2. ,  0. ],\n",
       "       [ 7.2,  6. ,  2. ,  2. ,  0. ],\n",
       "       [ 7.1,  4. ,  2. ,  2. ,  0. ],\n",
       "       [ 6.2,  4. ,  1. ,  2. ,  0. ],\n",
       "       [ 6.1,  2. ,  1. ,  3. ,  0. ],\n",
       "       [ 4.2,  2. ,  0. ,  3. ,  0. ],\n",
       "       [ 4.1,  0. ,  0. ,  3. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 16. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 17. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 18. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = real_data_splits_train[0][0][0]\n",
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "       [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "       [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "       [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "       [ 2.2, 14. ,  9. ,  1. ,  0. ],\n",
       "       [ 2.1, 12. ,  9. ,  2. ,  0. ],\n",
       "       [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "       [ 6.1, 12. ,  7. ,  2. ,  0. ],\n",
       "       [ 5.2, 12. ,  6. ,  2. ,  0. ],\n",
       "       [ 5.1, 10. ,  6. ,  2. ,  0. ],\n",
       "       [ 3.2, 10. ,  5. ,  2. ,  0. ],\n",
       "       [ 3.1,  8. ,  5. ,  2. ,  0. ],\n",
       "       [ 7.1,  8. ,  4. ,  2. ,  0. ],\n",
       "       [ 6.1,  8. ,  4. ,  2. ,  0. ],\n",
       "       [ 1.2,  8. ,  3. ,  2. ,  0. ],\n",
       "       [ 1.1,  6. ,  3. ,  2. ,  0. ],\n",
       "       [ 7.2,  6. ,  2. ,  2. ,  0. ],\n",
       "       [ 7.1,  4. ,  2. ,  2. ,  0. ],\n",
       "       [ 6.2,  4. ,  1. ,  2. ,  0. ],\n",
       "       [ 6.1,  2. ,  1. ,  3. ,  0. ],\n",
       "       [ 4.2,  2. ,  0. ,  3. ,  0. ],\n",
       "       [ 4.1,  0. ,  0. ,  3. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 16. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 17. ],\n",
       "       [ 0. ,  0. ,  0. ,  3. , 18. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_splits_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(game, components=[True, False, False, False, False]):#True, True, True, True]):\n",
    "    card_codes = np.zeros((7, 40))\n",
    "    cards_left = np.zeros((8, 40))\n",
    "    never_revealed_cards = np.zeros((14, 40))\n",
    "    max_same_card_reveals = np.zeros((20, 40))\n",
    "    rounds_since_done = np.zeros((27, 40))\n",
    "    \n",
    "    x_position = 0\n",
    "    \n",
    "    for step in game:\n",
    "        card_code = math.floor(step[0])\n",
    "        first_or_second = int(round((step[0] % 1) * 10))\n",
    "        \n",
    "        if card_code != 0:\n",
    "            card_codes[card_code - 1][x_position] = first_or_second\n",
    "            \n",
    "        cards_left[int(step[1] / 2)][x_position] = 1\n",
    "        never_revealed_cards[int(step[2])][x_position] = 1\n",
    "        max_same_card_reveals[int(step[3])][x_position] = 1\n",
    "        rounds_since_done[int(step[4])][x_position] = 1\n",
    "        \n",
    "        x_position += 1\n",
    "        \n",
    "    # Try leaving out some features and compare results!\n",
    "    image = np.zeros((0, 40))\n",
    "    if components[0]:   # Good visual feature for cnn.\n",
    "        image = np.vstack((image, card_codes))\n",
    "    if components[1]:\n",
    "        image = np.vstack((image, max_same_card_reveals))\n",
    "    if components[2]:   # I think good visual feature for cnn. \n",
    "        image = np.vstack((image, rounds_since_done))\n",
    "    if components[3]:\n",
    "        image = np.vstack((image, cards_left))\n",
    "    if components[4]:   # I think this feature is not very usefull for the cnn. \n",
    "                        # No big visual difference between being blinded an not. \n",
    "        image = np.vstack((image, never_revealed_cards))\n",
    "    #switched order of statistival features so that they have some space between them.\n",
    "        \n",
    "    return image#[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = create_image(game, components=[True, True, True, True, True])#[True, False, False, False, False])   #\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1657253f4c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing image reverted. More natural for humans, because higher values are higher. \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Step', fontsize=13)\n",
    "plt.ylabel('Stacked synthetic images of statistical features', fontsize=13)\n",
    "plt.imshow(image, origin='lower')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_for_split(data, components):\n",
    "    data_images = []\n",
    "    for split in trange(len(data)):\n",
    "        X = data[split][0]\n",
    "        y = data[split][1]\n",
    "        images = []\n",
    "        for game in range(len(X)):\n",
    "            image = create_image(X[game], components)\n",
    "            images.append(image)\n",
    "        split_data = ((images, y))\n",
    "        data_images.append(split_data)\n",
    "    return data_images\n",
    "    \n",
    "def create_images(components=[True, True, True, True, True]):\n",
    "    real_data_splits_train_images = create_images_for_split(real_data_splits_train, components)\n",
    "    real_data_splits_test_images = create_images_for_split(real_data_splits_test, components)\n",
    "    simulated_data_splits_train_images = create_images_for_split(simulated_data_splits_train, components)\n",
    "    return real_data_splits_train_images, real_data_splits_test_images, simulated_data_splits_train_images \n",
    "    #return real_data_splits_train_images[0][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_train_images, real_data_splits_test_images, simulated_data_splits_train_images = \\\n",
    "    create_images(components=[True, True, True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unclear noObst indices: 8?, 12\n",
    "# Unclear glare indices: 23, 26?, 27, 32, 36, \n",
    "# Not cortrect validated: glare in split 1, \n",
    "# Plan: remove and train best conigs and see if results get better \n",
    "\n",
    "plt.imshow(real_data_splits_train_images[0][0][19], origin='lower') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_participants_per_split = 19 # 20 but one is removed in each split for testing\n",
    "simulations_per_participant = 1000\n",
    "n_added_simulations_per_participant = 0\n",
    "n_runs = 5\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_simulated_data(X_train, y_train, simulated_train_set):\n",
    "    for n in range(n_added_simulations_per_participant):\n",
    "        for i in range(n_participants_per_split):\n",
    "\n",
    "            X_train_simulated_1 = simulated_train_set[0][(i * simulations_per_participant) + n]\n",
    "            y_train_simulated_1 = simulated_train_set[1][(i * simulations_per_participant) + n]\n",
    "            X_train_simulated_2 = simulated_train_set[0][(simulations_per_participant * n_participants_per_split) \\\n",
    "                                                         + (i * simulations_per_participant) + n]\n",
    "            y_train_simulated_2 = simulated_train_set[1][(simulations_per_participant * n_participants_per_split) \\\n",
    "                                                         + (i * simulations_per_participant) + n]\n",
    "            \n",
    "            X_train_simulated = np.concatenate((X_train_simulated_1[np.newaxis, :, :], \\\n",
    "                                               X_train_simulated_2[np.newaxis, :, :]), axis=0)\n",
    "            y_train_simulated = np.concatenate((y_train_simulated_1[np.newaxis, :], \\\n",
    "                                               y_train_simulated_2[np.newaxis, :]), axis=0)\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_train_simulated), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_simulated), axis=0)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score_of_run(histories, epochs):\n",
    "    mean_val_losses = []\n",
    "    mean_val_accuracies = []\n",
    "    mean_losses = []\n",
    "    mean_accuracies = []\n",
    "    for i in range(epochs):\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for l in range(len(histories)):\n",
    "            history = histories[l]\n",
    "            val_losses.append(history.history['val_loss'][i])\n",
    "            val_accuracies.append(history.history['val_accuracy'][i])\n",
    "            losses.append(history.history['loss'][i])\n",
    "            accuracies.append(history.history['accuracy'][i])\n",
    "        mean_val_losses.append(np.mean(val_losses))\n",
    "        mean_val_accuracies.append(np.mean(val_accuracies))\n",
    "        mean_losses.append(np.mean(losses))\n",
    "        mean_accuracies.append(np.mean(accuracies))\n",
    "    return mean_val_losses, mean_val_accuracies, mean_losses, mean_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score_over_all_runs(mean_run_scores, n_runs):\n",
    "    val_losses = np.asarray(mean_run_scores[0][0])\n",
    "    val_accuracies = np.asarray(mean_run_scores[0][1])\n",
    "    losses = np.asarray(mean_run_scores[0][2])\n",
    "    accuracies = np.asarray(mean_run_scores[0][3])\n",
    "                            \n",
    "    for i in range(1, n_runs):\n",
    "        val_losses += np.asarray(mean_run_scores[i][0])\n",
    "        val_accuracies += np.asarray(mean_run_scores[i][1])\n",
    "        losses += np.asarray(mean_run_scores[i][2])\n",
    "        accuracies += np.asarray(mean_run_scores[i][3])\n",
    "                                 \n",
    "    val_losses /= n_runs\n",
    "    val_accuracies /= n_runs\n",
    "    losses /= n_runs\n",
    "    accuracies /= n_runs\n",
    "    \n",
    "    return val_losses, val_accuracies, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train(X_train, y_train, X_test, y_test):\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    cnn_input_shape = X_train[0].shape\n",
    "    \n",
    "    #epochs = n_epochs\n",
    "    cnn_batch_size = 32 #1000\n",
    "    #verbose = 0\n",
    "    \n",
    "    #print(cnn_input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(76, 40,1), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=cnn_batch_size, verbose=0, \n",
    "                        shuffle=True, validation_data=(X_test, y_test))\n",
    "    \n",
    "    #print(history.history['val_accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 72, 36, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 70, 34, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 35, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19040)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2437248   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 2,463,928\n",
      "Trainable params: 2,463,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(76, 40,1), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))#, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Sequential()\n",
    "\n",
    "test_model.add(Conv2D(32, (5, 5), input_shape=(76, 40,1), activation='relu'))\n",
    "test_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "test_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "test_model.add(Dropout(0.5))\n",
    "\n",
    "test_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "test_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "test_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "test_model.add(Dropout(0.5))\n",
    "\n",
    "test_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "test_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "test_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "test_model.add(Dropout(0.5))\n",
    "\n",
    "test_model.add(Flatten())\n",
    "test_model.add(Dense(128, activation='relu'))\n",
    "test_model.add(Dense(64, activation='relu'))\n",
    "test_model.add(Dense(2, activation='softmax'))\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Step', fontsize=20)\n",
    "plt.ylabel('Dynamic card codes')\n",
    "plt.imshow(image, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in test_model.layers]\n",
    "activation_model = keras.models.Model(inputs=test_model.input, outputs=layer_outputs)\n",
    "img = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "img_tensor = np.expand_dims(img, axis=0)\n",
    "#img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "activations = activation_model.predict(img_tensor) \n",
    "first_layer_activation = activations[1]\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "for layer in test_model.layers[:12]:\n",
    "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
    "    \n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, # Displays the grid\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_run_scores = []\n",
    "for i in trange(n_runs, desc='Runs'): \n",
    "    histories = []\n",
    "    for train_set, test_set, simulated_train_set in tqdm(zip(real_data_splits_train_images, \\\n",
    "                                    real_data_splits_test_images, simulated_data_splits_train_images), total=20, desc='Folds'):\n",
    "        \n",
    "        X_train = train_set[0]\n",
    "        y_train = train_set[1]\n",
    "        X_test = test_set[0]\n",
    "        y_test = test_set[1]\n",
    "        \n",
    "        #print(X_test[0])\n",
    "        \n",
    "        #plt.imshow(X_test[1], origin='lower') \n",
    "        \n",
    "        # Adding simulated data. \n",
    "        X_train, y_train = add_simulated_data(X_train, y_train, simulated_train_set)   \n",
    "        \n",
    "        print(X_train[0].shape)\n",
    "        print(y_train.shape) \n",
    "        exit()\n",
    "\n",
    "        # Shuffling training data\n",
    "        temp_train = list(zip(X_train, y_train.tolist()))\n",
    "        random.shuffle(temp_train)\n",
    "        X_train, y_train = zip(*temp_train)\n",
    "        \n",
    "        create_and_train(np.asarray(X_train), np.asarray(y_train), np.asarray(X_test), y_test)\n",
    "        \n",
    "    mean_run_score = mean_score_of_run(histories=histories, epochs=n_epochs)\n",
    "    mean_run_scores.append(mean_run_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val_losses, mean_val_accuracies, mean_losses, mean_accuracies = mean_score_over_all_runs(mean_run_scores, n_runs)\n",
    "mean_val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('glareObs_noAdapt: Best validation accuracy %s%% (at epoch %s)' \\\n",
    "          %(round(mean_val_accuracies.max() * 100, 2), np.argmax(mean_val_accuracies) + 1))\n",
    "plt.plot(mean_accuracies)\n",
    "plt.plot(mean_val_accuracies)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train(RD_SD%sx)' %n_added_simulations_per_participant, 'validation(RD)'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('glareObs_noAdapt: Lowest validation loss %s (at epoch %s)' \\\n",
    "          %(round(mean_val_losses.min(), 4), np.argmin(mean_val_losses) + 1))\n",
    "plt.plot(mean_losses)\n",
    "plt.plot(mean_val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train(RD_SD%sx)' %n_added_simulations_per_participant, 'validation(RD)'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
