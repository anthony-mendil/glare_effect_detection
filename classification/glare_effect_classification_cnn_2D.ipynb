{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling2D, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_splits(base_path='C:\\\\Users\\\\dylin\\\\Documents\\\\BA_Glare_Effect\\\\classification_data\\\\features\\\\', splits=20):\n",
    "    real_data_splits_train = []\n",
    "    real_data_splits_test = []\n",
    "    simulated_data_splits_train = []\n",
    "    for split in range(1, splits + 1):\n",
    "        # Real data for training\n",
    "        X_realData_train = np.load(base_path + 'real\\\\Split%s\\\\for_simulation\\\\X_realData_train.npy' %str(split))\n",
    "        y_realData_train = np.load(base_path + 'real\\\\Split%s\\\\for_simulation\\\\y_realData_train.npy' %str(split))\n",
    "        real_data_splits_train.append((X_realData_train, y_realData_train))\n",
    "        \n",
    "        # Real data for testing\n",
    "        X_realData_test = np.load(base_path + 'real\\\\Split%s\\\\for_testing\\\\X_realData_test.npy' %str(split))\n",
    "        y_realData_test = np.load(base_path + 'real\\\\Split%s\\\\for_testing\\\\y_realData_test.npy' %str(split))\n",
    "        real_data_splits_test.append((X_realData_test, y_realData_test))\n",
    "    \n",
    "        # Simulated data for training\n",
    "        X_simulatedData_train = np.load(base_path + 'simulated\\\\Split%s\\\\X_simulatedData_train.npy' %str(split))\n",
    "        y_simulatedData_train = np.load(base_path + 'simulated\\\\Split%s\\\\y_simulatedData_train.npy' %str(split))\n",
    "        simulated_data_splits_train.append((X_simulatedData_train, y_simulatedData_train))\n",
    "    return real_data_splits_train, real_data_splits_test, simulated_data_splits_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_train, real_data_splits_test, simulated_data_splits_train = load_data_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = real_data_splits_train[0][0][0]\n",
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(game, components=[True, True, True, True, True]):\n",
    "    card_codes = np.zeros((7, 40))\n",
    "    cards_left = np.zeros((8, 40))\n",
    "    never_revealed_cards = np.zeros((14, 40))\n",
    "    max_same_card_reveals = np.zeros((21, 40))\n",
    "    rounds_since_done = np.zeros((25, 40))\n",
    "    \n",
    "    x_position = 0\n",
    "    \n",
    "    for step in game:\n",
    "        card_code = math.floor(step[0])\n",
    "        first_or_second = int(round((step[0] % 1) * 10))\n",
    "        \n",
    "        if card_code != 0:\n",
    "            card_codes[card_code - 1][x_position] = first_or_second\n",
    "            \n",
    "        cards_left[int(step[1] / 2)][x_position] = 1\n",
    "        never_revealed_cards[int(step[2])][x_position] = 1\n",
    "        max_same_card_reveals[int(step[3])][x_position] = 1\n",
    "        rounds_since_done[int(step[4])][x_position] = 1\n",
    "        \n",
    "        x_position += 1\n",
    "        \n",
    "    # Try leaving out some features and compare results!\n",
    "    image = np.zeros((0, 40))\n",
    "    if components[0]:   # Good visual feature for cnn.\n",
    "        image = np.vstack((image, card_codes))\n",
    "    if components[1]:\n",
    "        image = np.vstack((image, max_same_card_reveals))\n",
    "    if components[2]:   # I think good visual feature for cnn. \n",
    "        image = np.vstack((image, rounds_since_done))\n",
    "    if components[3]:\n",
    "        image = np.vstack((image, cards_left))\n",
    "    if components[4]:   # I think this feature is not very usefull for the cnn. \n",
    "                        # No big visual difference between being blinded an not. \n",
    "        image = np.vstack((image, never_revealed_cards))\n",
    "    #switched order of statistival features so that they have some space between them.\n",
    "        \n",
    "    return image#[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = create_image(game, components=[True, True, True, True, True])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing image reverted. More natural for humans, because higher values are higher. \n",
    "plt.imshow(image, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_for_split(data, components):\n",
    "    data_images = []\n",
    "    for split in trange(len(data)):\n",
    "        X = data[split][0]\n",
    "        y = data[split][1]\n",
    "        images = []\n",
    "        for game in range(len(X)):\n",
    "            image = create_image(X[game], components)\n",
    "            images.append(image)\n",
    "        split_data = ((images, y))\n",
    "        data_images.append(split_data)\n",
    "    return data_images\n",
    "    \n",
    "def create_images(components=[True, True, True, True, True]):\n",
    "    real_data_splits_train_images = create_images_for_split(real_data_splits_train, components)\n",
    "    real_data_splits_test_images = create_images_for_split(real_data_splits_test, components)\n",
    "    simulated_data_splits_train_images = create_images_for_split(simulated_data_splits_train, components)\n",
    "    return real_data_splits_train_images, real_data_splits_test_images, simulated_data_splits_train_images \n",
    "    #return real_data_splits_train_images[0][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_train_images, real_data_splits_test_images, simulated_data_splits_train_images = \\\n",
    "    create_images(components=[True, True, True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unclear noObst indices: 8?, 12\n",
    "# Unclear glare indices: 23, 26?, 27, 32, 36, \n",
    "# Not cortrect validated: glare in split 1, \n",
    "# Plan: remove and train best conigs and see if results get better \n",
    "\n",
    "plt.imshow(real_data_splits_train_images[0][0][19], origin='lower') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_splits_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_participants_per_split = 19 # 20 but one is removed in each split for testing\n",
    "simulations_per_participant = 1000\n",
    "n_added_simulations_per_participant = 20\n",
    "n_runs = 20\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_simulated_data(X_train, y_train, simulated_train_set):\n",
    "    for n in range(n_added_simulations_per_participant):\n",
    "        for i in range(n_participants_per_split):\n",
    "\n",
    "            X_train_simulated_1 = simulated_train_set[0][(i * simulations_per_participant) + n]\n",
    "            y_train_simulated_1 = simulated_train_set[1][(i * simulations_per_participant) + n]\n",
    "            X_train_simulated_2 = simulated_train_set[0][(simulations_per_participant * n_participants_per_split) \\\n",
    "                                                         + (i * simulations_per_participant) + n]\n",
    "            y_train_simulated_2 = simulated_train_set[1][(simulations_per_participant * n_participants_per_split) \\\n",
    "                                                         + (i * simulations_per_participant) + n]\n",
    "            \n",
    "            X_train_simulated = np.concatenate((X_train_simulated_1[np.newaxis, :, :], \\\n",
    "                                               X_train_simulated_2[np.newaxis, :, :]), axis=0)\n",
    "            y_train_simulated = np.concatenate((y_train_simulated_1[np.newaxis, :], \\\n",
    "                                               y_train_simulated_2[np.newaxis, :]), axis=0)\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_train_simulated), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_simulated), axis=0)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score_of_run(histories, epochs):\n",
    "    mean_val_losses = []\n",
    "    mean_val_accuracies = []\n",
    "    mean_losses = []\n",
    "    mean_accuracies = []\n",
    "    for i in range(epochs):\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for l in range(len(histories)):\n",
    "            history = histories[l]\n",
    "            val_losses.append(history.history['val_loss'][i])\n",
    "            val_accuracies.append(history.history['val_accuracy'][i])\n",
    "            losses.append(history.history['loss'][i])\n",
    "            accuracies.append(history.history['accuracy'][i])\n",
    "        mean_val_losses.append(np.mean(val_losses))\n",
    "        mean_val_accuracies.append(np.mean(val_accuracies))\n",
    "        mean_losses.append(np.mean(losses))\n",
    "        mean_accuracies.append(np.mean(accuracies))\n",
    "    return mean_val_losses, mean_val_accuracies, mean_losses, mean_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_score_over_all_runs(mean_run_scores, n_runs):\n",
    "    val_losses = np.asarray(mean_run_scores[0][0])\n",
    "    val_accuracies = np.asarray(mean_run_scores[0][1])\n",
    "    losses = np.asarray(mean_run_scores[0][2])\n",
    "    accuracies = np.asarray(mean_run_scores[0][3])\n",
    "                            \n",
    "    for i in range(1, n_runs):\n",
    "        val_losses += np.asarray(mean_run_scores[i][0])\n",
    "        val_accuracies += np.asarray(mean_run_scores[i][1])\n",
    "        losses += np.asarray(mean_run_scores[i][2])\n",
    "        accuracies += np.asarray(mean_run_scores[i][3])\n",
    "                                 \n",
    "    val_losses /= n_runs\n",
    "    val_accuracies /= n_runs\n",
    "    losses /= n_runs\n",
    "    accuracies /= n_runs\n",
    "    \n",
    "    return val_losses, val_accuracies, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train(X_train, y_train, X_test, y_test):\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    cnn_input_shape = X_train[0].shape\n",
    "    #epochs = n_epochs\n",
    "    cnn_batch_size = 32 #1000\n",
    "    #verbose = 0\n",
    "    \n",
    "    #print(cnn_input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=cnn_input_shape, activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    #model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=cnn_batch_size, verbose=0, \n",
    "                        shuffle=True, validation_data=(X_test, y_test))\n",
    "    \n",
    "    #print(history.history['val_accuracy'])\n",
    "    \n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_run_scores = []\n",
    "for i in trange(n_runs, desc='Runs'): \n",
    "    histories = []\n",
    "    for train_set, test_set, simulated_train_set in tqdm(zip(real_data_splits_train_images, \\\n",
    "                                    real_data_splits_test_images, simulated_data_splits_train_images), total=20, desc='Folds'):\n",
    "        \n",
    "        X_train = train_set[0]\n",
    "        y_train = train_set[1]\n",
    "        X_test = test_set[0]\n",
    "        y_test = test_set[1]\n",
    "        \n",
    "        #print(X_test[0])\n",
    "        \n",
    "        #plt.imshow(X_test[1], origin='lower') \n",
    "        \n",
    "        # Adding simulated data. \n",
    "        X_train, y_train = add_simulated_data(X_train, y_train, simulated_train_set)   \n",
    "        \n",
    "        #print(X_train.shape)\n",
    "        #print(y_train.shape) \n",
    "\n",
    "        # Shuffling training data\n",
    "        temp_train = list(zip(X_train, y_train.tolist()))\n",
    "        random.shuffle(temp_train)\n",
    "        X_train, y_train = zip(*temp_train)\n",
    "        \n",
    "        create_and_train(np.asarray(X_train), np.asarray(y_train), np.asarray(X_test), y_test)\n",
    "        \n",
    "    mean_run_score = mean_score_of_run(histories=histories, epochs=n_epochs)\n",
    "    mean_run_scores.append(mean_run_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val_losses, mean_val_accuracies, mean_losses, mean_accuracies = mean_score_over_all_runs(mean_run_scores, n_runs)\n",
    "mean_val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('glareObs_noAdapt: Best validation accuracy %s%% (at epoch %s)' \\\n",
    "          %(round(mean_val_accuracies.max() * 100, 2), np.argmax(mean_val_accuracies) + 1))\n",
    "plt.plot(mean_accuracies)\n",
    "plt.plot(mean_val_accuracies)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train(RD_SD%sx)' %n_added_simulations_per_participant, 'validation(RD)'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('glareObs_noAdapt: Lowest validation loss %s (at epoch %s)' \\\n",
    "          %(round(mean_val_losses.min(), 4), np.argmin(mean_val_losses) + 1))\n",
    "plt.plot(mean_losses)\n",
    "plt.plot(mean_val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train(RD_SD%sx)' %n_added_simulations_per_participant, 'validation(RD)'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
