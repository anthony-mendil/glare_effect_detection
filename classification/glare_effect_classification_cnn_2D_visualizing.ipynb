{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling2D, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data_splits(base_path='C:\\\\Users\\\\dylin\\\\Documents\\\\BA_Glare_Effect\\\\classification_data_initial\\\\features\\\\', splits=20):\n",
    "    real_data_splits_train = []\n",
    "    real_data_splits_test = []\n",
    "    simulated_data_splits_train = []\n",
    "    for split in range(1, splits + 1):\n",
    "        # Real data for training\n",
    "        X_realData_train = np.load(base_path + 'real\\\\Split%s\\\\for_simulation\\\\X_realData_train.npy' %str(split))\n",
    "        y_realData_train = np.load(base_path + 'real\\\\Split%s\\\\for_simulation\\\\y_realData_train.npy' %str(split))\n",
    "        real_data_splits_train.append((X_realData_train, y_realData_train))\n",
    "        \n",
    "        # Real data for testing\n",
    "        X_realData_test = np.load(base_path + 'real\\\\Split%s\\\\for_testing\\\\X_realData_test.npy' %str(split))\n",
    "        y_realData_test = np.load(base_path + 'real\\\\Split%s\\\\for_testing\\\\y_realData_test.npy' %str(split))\n",
    "        real_data_splits_test.append((X_realData_test, y_realData_test))\n",
    "    \n",
    "        # Simulated data for training\n",
    "        X_simulatedData_train = np.load(base_path + 'simulated\\\\Split%s\\\\X_simulatedData_train.npy' %str(split))\n",
    "        y_simulatedData_train = np.load(base_path + 'simulated\\\\Split%s\\\\y_simulatedData_train.npy' %str(split))\n",
    "        simulated_data_splits_train.append((X_simulatedData_train, y_simulatedData_train))\n",
    "    return real_data_splits_train, real_data_splits_test, simulated_data_splits_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_data_splits_train, real_data_splits_test, simulated_data_splits_train = load_data_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_data_split_train, real_data_split_test, simulated_data_split_train = \\\n",
    "    real_data_splits_train[0], real_data_splits_test[0], simulated_data_splits_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_split_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_image(game, components=[True, True, True, True, True]):\n",
    "    card_codes = np.zeros((7, 40))\n",
    "    cards_left = np.zeros((8, 40))\n",
    "    never_revealed_cards = np.zeros((14, 40))\n",
    "    max_same_card_reveals = np.zeros((20, 40))\n",
    "    rounds_since_done = np.zeros((27, 40))\n",
    "    \n",
    "    x_position = 0\n",
    "    \n",
    "    for step in game:\n",
    "        card_code = math.floor(step[0])\n",
    "        first_or_second = int(round((step[0] % 1) * 10))\n",
    "        \n",
    "        if card_code != 0:\n",
    "            card_codes[card_code - 1][x_position] = first_or_second\n",
    "            \n",
    "        cards_left[int(step[1] / 2)][x_position] = 1\n",
    "        never_revealed_cards[int(step[2])][x_position] = 1\n",
    "        max_same_card_reveals[int(step[3])][x_position] = 1\n",
    "        rounds_since_done[int(step[4])][x_position] = 1\n",
    "        \n",
    "        x_position += 1\n",
    "        \n",
    "    # Try leaving out some features and compare results!\n",
    "    image = np.zeros((0, 40))\n",
    "    if components[0]:   # Good visual feature for cnn.\n",
    "        image = np.vstack((image, card_codes))\n",
    "    if components[1]:\n",
    "        image = np.vstack((image, max_same_card_reveals))\n",
    "    if components[2]:   # I think good visual feature for cnn. \n",
    "        image = np.vstack((image, rounds_since_done))\n",
    "    if components[3]:\n",
    "        image = np.vstack((image, cards_left))\n",
    "    if components[4]:   # I think this feature is not very usefull for the cnn. \n",
    "                        # No big visual difference between being blinded an not. \n",
    "        image = np.vstack((image, never_revealed_cards))\n",
    "    #switched order of statistival features so that they have some space between them.\n",
    "        \n",
    "    return image#[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_images_for_split(data, components):\n",
    "    data_images = []\n",
    "    for split in trange(len(data)):\n",
    "        X = data[split][0]\n",
    "        y = data[split][1]\n",
    "        images = []\n",
    "        for game in range(len(X)):\n",
    "            image = create_image(X[game], components)\n",
    "            images.append(image)\n",
    "        split_data = ((images, y))\n",
    "        data_images.append(split_data)\n",
    "    return data_images\n",
    "    \n",
    "def create_images(components=[True, True, True, True, True]):\n",
    "    real_data_splits_train_images = create_images_for_split(real_data_splits_train, components)\n",
    "    real_data_splits_test_images = create_images_for_split(real_data_splits_test, components)\n",
    "    simulated_data_splits_train_images = create_images_for_split(simulated_data_splits_train, components)\n",
    "    return real_data_splits_train_images, real_data_splits_test_images, simulated_data_splits_train_images \n",
    "    #return real_data_splits_train_images[0][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16014c436e044a16a276d70b8f38e061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0ef9ec62e9430587db95654ae338c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f503ffb9043b4cb1930e6c96b9803348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "real_data_splits_train_images, real_data_splits_test_images, simulated_data_splits_train_images = \\\n",
    "    create_images(components=[True, True, True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20e2f9589c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unclear noObst indices: 8?, 12\n",
    "# Unclear glare indices: 23, 26?, 27, 32, 36, \n",
    "# Not cortrect validated: glare in split 1, \n",
    "# Plan: remove and train best conigs and see if results get better \n",
    "\n",
    "plt.imshow(real_data_splits_train_images[0][0][19], origin='lower') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_splits_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 1.2, 12. , 12. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  1. ,  0. ],\n",
       "          [ 5.2, 12. ,  7. ,  1. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.2,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 4.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 2.1,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 7.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 4.2,  4. ,  0. ,  2. ,  0. ],\n",
       "          [ 6.1,  4. ,  0. ,  2. ,  0. ],\n",
       "          [ 4.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.1,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 16. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 3.2, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  1. ,  0. ],\n",
       "          [ 4.2, 12. ,  7. ,  1. ,  0. ],\n",
       "          [ 4.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 6.2,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 1.1,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 1.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 7.1,  6. ,  1. ,  2. ,  0. ],\n",
       "          [ 2.2,  6. ,  1. ,  2. ,  0. ],\n",
       "          [ 5.2,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.1,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 5.1,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 5.2,  4. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 12. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 6.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 5.2, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.1,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 7.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 1.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 1.1,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 7.1,  4. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 6.1,  2. ,  1. ,  3. ,  0. ],\n",
       "          [ 4.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 16. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 17. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 18. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  8. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  8. ,  3. ,  0. ],\n",
       "          [ 1.1, 14. ,  8. ,  4. ,  0. ],\n",
       "          [ 5.2, 14. ,  7. ,  4. ,  0. ],\n",
       "          [ 5.1, 12. ,  7. ,  4. ,  0. ],\n",
       "          [ 6.1, 12. ,  6. ,  4. ,  0. ],\n",
       "          [ 1.1, 12. ,  6. ,  5. ,  0. ],\n",
       "          [ 2.2, 12. ,  5. ,  5. ,  0. ],\n",
       "          [ 6.1, 12. ,  5. ,  5. ,  0. ],\n",
       "          [ 6.1, 12. ,  5. ,  5. ,  0. ],\n",
       "          [ 3.2, 12. ,  5. ,  5. ,  0. ],\n",
       "          [ 6.2, 12. ,  4. ,  5. ,  0. ],\n",
       "          [ 1.1, 12. ,  4. ,  6. ,  0. ],\n",
       "          [ 2.2, 12. ,  4. ,  6. ,  0. ],\n",
       "          [ 6.1, 12. ,  4. ,  6. ,  0. ],\n",
       "          [ 1.2, 12. ,  3. ,  6. ,  0. ],\n",
       "          [ 6.1, 12. ,  3. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  2. ,  6. ,  0. ],\n",
       "          [ 6.1, 12. ,  2. ,  6. ,  0. ],\n",
       "          [ 6.2, 12. ,  2. ,  6. ,  0. ],\n",
       "          [ 7.1, 12. ,  1. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  1. ,  6. ,  0. ],\n",
       "          [ 7.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 1.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 3.1, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 2.1, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 4.1, 10. ,  0. ,  6. ,  0. ],\n",
       "          [ 3.2, 10. ,  0. ,  6. ,  0. ],\n",
       "          [ 1.2, 10. ,  0. ,  6. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 3.2, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.2, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 2.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 6.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.1,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 1.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 2.2,  8. ,  1. ,  2. ,  0. ],\n",
       "          [ 2.1,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.1,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 6.1, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 7.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 7.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.1, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 1.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 4.2, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 4.2,  8. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  2. ,  3. ,  0. ],\n",
       "          [ 5.2,  8. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.1,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 4.2, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 1.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.1,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.1,  6. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.1,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 3.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 2.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.1,  6. ,  2. ,  4. ,  0. ],\n",
       "          [ 3.2,  4. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.2,  4. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.1,  2. ,  1. ,  4. ,  0. ],\n",
       "          [ 2.2,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 14. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.2, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  8. ,  3. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  3. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 2.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  5. ,  4. ,  0. ],\n",
       "          [ 2.1, 10. ,  5. ,  4. ,  0. ],\n",
       "          [ 4.2, 10. ,  4. ,  4. ,  0. ],\n",
       "          [ 7.2, 10. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.1, 10. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.2,  8. ,  3. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.2,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.2,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.2,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.1,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.2,  2. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 6.1, 14. ,  8. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 7.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.2, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.2, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 5.1,  8. ,  2. ,  3. ,  0. ],\n",
       "          [ 5.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 1.2,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 1.1,  4. ,  1. ,  3. ,  0. ],\n",
       "          [ 2.2,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.2,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 1.2, 12. , 12. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 6.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.2, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 4.1, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 2.2, 12. ,  3. ,  3. ,  0. ],\n",
       "          [ 4.2, 12. ,  2. ,  3. ,  0. ],\n",
       "          [ 6.1, 12. ,  2. ,  3. ,  0. ],\n",
       "          [ 6.2, 12. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.1, 12. ,  1. ,  3. ,  0. ],\n",
       "          [ 5.2, 12. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.1, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.1, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.2, 10. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 3.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1,  4. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 3.2, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 2.2, 12. ,  8. ,  1. ,  0. ],\n",
       "          [ 1.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.2, 10. ,  8. ,  3. ,  0. ],\n",
       "          [ 4.2, 10. ,  7. ,  3. ,  0. ],\n",
       "          [ 4.1,  8. ,  7. ,  3. ,  0. ],\n",
       "          [ 5.1,  8. ,  6. ,  3. ,  0. ],\n",
       "          [ 6.1,  8. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 7.2,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 1.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 1.1,  4. ,  2. ,  3. ,  0. ],\n",
       "          [ 6.2,  4. ,  1. ,  3. ,  0. ],\n",
       "          [ 6.1,  2. ,  1. ,  3. ,  0. ],\n",
       "          [ 5.1,  2. ,  1. ,  3. ,  0. ],\n",
       "          [ 5.2,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 16. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 17. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 18. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 6.1, 14. ,  8. ,  1. ,  0. ],\n",
       "          [ 1.2, 14. ,  7. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 1.1, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 1.2, 10. ,  6. ,  3. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.2, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 6.2, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 3.2, 10. ,  2. ,  3. ,  0. ],\n",
       "          [ 5.2, 10. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.2, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.1, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  0. ,  0. ,  5. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  6. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 6.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 1.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.2, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 1.1, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.1, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.2, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 1.2, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 1.1,  8. ,  4. ,  4. ,  0. ],\n",
       "          [ 3.2,  8. ,  4. ,  4. ,  0. ],\n",
       "          [ 6.1,  8. ,  4. ,  4. ,  0. ],\n",
       "          [ 7.1,  8. ,  3. ,  4. ,  0. ],\n",
       "          [ 3.2,  8. ,  3. ,  4. ,  0. ],\n",
       "          [ 3.1,  8. ,  3. ,  4. ,  0. ],\n",
       "          [ 3.2,  6. ,  3. ,  4. ,  0. ],\n",
       "          [ 4.1,  6. ,  3. ,  4. ,  0. ],\n",
       "          [ 6.1,  6. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.1,  6. ,  3. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  2. ,  4. ,  0. ],\n",
       "          [ 4.1,  6. ,  2. ,  4. ,  0. ],\n",
       "          [ 4.2,  4. ,  2. ,  4. ,  0. ],\n",
       "          [ 6.2,  4. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  2. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.1,  2. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.2,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 2.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 1.1, 12. ,  7. ,  3. ,  0. ],\n",
       "          [ 4.2, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  6. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 1.2, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 3.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 1.1, 10. ,  4. ,  4. ,  0. ],\n",
       "          [ 3.2, 10. ,  3. ,  4. ,  0. ],\n",
       "          [ 3.1,  8. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.2,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.1,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 1.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 7.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  6. ,  0. ],\n",
       "          [ 7.2,  8. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.2,  8. ,  0. ,  6. ,  0. ],\n",
       "          [ 1.1,  8. ,  0. ,  6. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  7. ,  0. ],\n",
       "          [ 1.2,  8. ,  0. ,  7. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  8. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 1.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.2, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 3.1,  6. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.1,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 4.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.1,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 4.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 4.1,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 4.2,  4. ,  2. ,  3. ,  0. ],\n",
       "          [ 7.2,  4. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.1,  2. ,  1. ,  3. ,  0. ],\n",
       "          [ 6.1,  2. ,  1. ,  3. ,  0. ],\n",
       "          [ 6.2,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  3. ,  0. ],\n",
       "          [ 3.1, 14. , 10. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  3. ,  0. ],\n",
       "          [ 2.1, 14. , 10. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 3.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 1.1, 14. ,  9. ,  4. ,  0. ],\n",
       "          [ 4.1, 14. ,  9. ,  4. ,  0. ],\n",
       "          [ 2.2, 14. ,  8. ,  4. ,  0. ],\n",
       "          [ 6.1, 14. ,  7. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  6. ,  4. ,  0. ],\n",
       "          [ 6.1, 14. ,  6. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  6. ,  4. ,  0. ],\n",
       "          [ 2.2, 14. ,  6. ,  4. ,  0. ],\n",
       "          [ 5.1, 14. ,  6. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  5. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  5. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  5. ,  4. ,  0. ],\n",
       "          [ 5.2, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 4.1, 14. ,  4. ,  5. ,  0. ],\n",
       "          [ 2.2, 14. ,  4. ,  5. ,  0. ],\n",
       "          [ 5.2, 14. ,  4. ,  5. ,  0. ],\n",
       "          [ 3.2, 14. ,  3. ,  5. ,  0. ],\n",
       "          [ 1.1, 14. ,  3. ,  5. ,  0. ],\n",
       "          [ 4.2, 14. ,  2. ,  5. ,  0. ],\n",
       "          [ 5.2, 14. ,  2. ,  5. ,  0. ],\n",
       "          [ 1.2, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 1.1, 12. ,  1. ,  6. ,  0. ],\n",
       "          [ 7.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  6. ,  0. ],\n",
       "          [ 7.1, 12. ,  0. ,  6. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.2, 10. ,  9. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 4.2, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.2, 10. ,  3. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  3. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1, 10. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 6.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 5.2,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 4.1,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 10. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 2.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.2, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 1.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 7.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.2, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.2, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 7.1, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 2.1, 12. ,  4. ,  4. ,  0. ],\n",
       "          [ 6.1, 12. ,  4. ,  4. ,  0. ],\n",
       "          [ 6.2, 10. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.2, 10. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.1, 10. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.2, 10. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.1,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.1,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.2,  6. ,  2. ,  4. ,  0. ],\n",
       "          [ 3.2,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 3.1,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 3.2,  2. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.1,  2. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.2,  0. ,  0. ,  5. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  4. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 1.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 4.2, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.2, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.2, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 7.1, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 2.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.2,  8. ,  1. ,  2. ,  0. ],\n",
       "          [ 2.1,  8. ,  1. ,  2. ,  0. ],\n",
       "          [ 3.2,  8. ,  0. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  0. ,  2. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 3.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 3.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.2,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 4.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 4.2, 12. ,  9. ,  3. ,  0. ],\n",
       "          [ 3.2, 12. ,  8. ,  3. ,  0. ],\n",
       "          [ 3.1, 10. ,  8. ,  3. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  3. ,  0. ],\n",
       "          [ 1.2, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.2, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.2, 10. ,  2. ,  3. ,  0. ],\n",
       "          [ 6.1,  8. ,  2. ,  3. ,  0. ],\n",
       "          [ 7.2,  8. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.1,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.2,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 12. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 4.2, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 1.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 5.2,  8. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.1,  8. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.2,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 7.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 7.1,  4. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.2,  4. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.1,  2. ,  1. ,  3. ,  0. ],\n",
       "          [ 1.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.1,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 1.2, 12. , 12. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 3.2, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 3.1, 10. ,  9. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.1, 10. ,  7. ,  3. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  3. ,  0. ],\n",
       "          [ 4.2, 10. ,  6. ,  3. ,  0. ],\n",
       "          [ 4.1,  8. ,  6. ,  3. ,  0. ],\n",
       "          [ 2.2,  8. ,  5. ,  3. ,  0. ],\n",
       "          [ 6.1,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 2.2,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.1,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  3. ,  3. ,  0. ],\n",
       "          [ 2.1,  8. ,  3. ,  4. ,  0. ],\n",
       "          [ 5.2,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.1,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.1,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 6.2,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.2,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 7.1,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 6.1,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.2,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.1,  6. ,  0. ,  6. ,  0. ],\n",
       "          [ 5.2,  4. ,  0. ,  6. ,  0. ],\n",
       "          [ 7.1,  4. ,  0. ,  6. ,  0. ],\n",
       "          [ 6.2,  4. ,  0. ,  6. ,  0. ],\n",
       "          [ 6.1,  4. ,  0. ,  6. ,  0. ],\n",
       "          [ 7.1,  4. ,  0. ,  6. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.2, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.1, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 4.1,  8. ,  2. ,  2. ,  0. ],\n",
       "          [ 4.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 1.1,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 1.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 7.2,  4. ,  0. ,  2. ,  0. ],\n",
       "          [ 7.1,  2. ,  0. ,  2. ,  0. ],\n",
       "          [ 5.2,  2. ,  0. ,  2. ,  0. ],\n",
       "          [ 5.1,  0. ,  0. ,  2. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 16. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 1.2, 12. , 12. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  1. ,  0. ],\n",
       "          [ 6.1, 12. ,  7. ,  1. ,  0. ],\n",
       "          [ 3.2, 12. ,  6. ,  1. ,  0. ],\n",
       "          [ 6.2, 12. ,  5. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. ,  5. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 4.2, 12. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1, 12. ,  2. ,  2. ,  0. ],\n",
       "          [ 5.2, 12. ,  1. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.2, 10. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.2,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.1,  8. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 3.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  5. ,  0. ],\n",
       "          [ 3.2,  6. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  9. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 1.2, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 1.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 1.2,  8. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.1,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.2,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 7.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 4.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 5.2,  4. ,  0. ,  2. ,  0. ],\n",
       "          [ 5.1,  4. ,  0. ,  2. ,  0. ],\n",
       "          [ 5.2,  2. ,  0. ,  2. ,  0. ],\n",
       "          [ 4.1,  2. ,  0. ,  2. ,  0. ],\n",
       "          [ 4.2,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 16. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 5.1, 14. ,  8. ,  1. ,  0. ],\n",
       "          [ 5.2, 14. ,  7. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 1.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 2.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 2.2, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 6.1, 14. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.2, 14. ,  4. ,  3. ,  0. ],\n",
       "          [ 2.2, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 6.1, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 4.2, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 1.2, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 6.1, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 3.1, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 5.2, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 2.1, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.2, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 3.1, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.2, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.2, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.1, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 4.1, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 6.1, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 6.2, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 2.2, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 7.1, 14. ,  1. ,  5. ,  0. ],\n",
       "          [ 3.2, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 7.1, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 1.2, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 1.1, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.1, 14. ,  0. ,  6. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 3.2, 14. ,  8. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 6.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 7.1, 14. ,  5. ,  2. ,  0. ],\n",
       "          [ 7.2, 14. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.1, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  4. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  3. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  3. ,  3. ,  0. ],\n",
       "          [ 5.2, 12. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.1, 12. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.2, 10. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.1, 10. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.2,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 4.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.2,  2. ,  0. ,  5. ,  0. ],\n",
       "          [ 1.1,  2. ,  0. ,  5. ,  0. ],\n",
       "          [ 1.2,  0. ,  0. ,  5. ,  0. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 4.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 6.1, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.2, 14. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.2, 14. ,  4. ,  2. ,  0. ],\n",
       "          [ 2.1, 14. ,  4. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  4. ,  2. ,  0. ],\n",
       "          [ 4.2, 14. ,  4. ,  2. ,  0. ],\n",
       "          [ 1.2, 14. ,  3. ,  2. ,  0. ],\n",
       "          [ 1.2, 14. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.2, 14. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1, 14. ,  2. ,  2. ,  0. ],\n",
       "          [ 7.2, 12. ,  1. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  1. ,  3. ,  0. ],\n",
       "          [ 1.1, 12. ,  1. ,  3. ,  0. ],\n",
       "          [ 2.1, 12. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.2, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.1, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.2, 10. ,  1. ,  5. ,  0. ],\n",
       "          [ 6.2, 10. ,  1. ,  5. ,  0. ],\n",
       "          [ 1.2, 10. ,  1. ,  5. ,  0. ],\n",
       "          [ 2.2, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.2, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.2, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.2, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.1, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.1, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.1, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.1, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 3.2, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 1.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 2.2, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 2.1, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 2.2,  8. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 5.1,  6. ,  5. ,  2. ,  0. ],\n",
       "          [ 4.2,  6. ,  4. ,  2. ,  0. ],\n",
       "          [ 4.1,  4. ,  4. ,  2. ,  0. ],\n",
       "          [ 6.1,  4. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1,  4. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 6.1,  2. ,  1. ,  2. ,  0. ],\n",
       "          [ 7.2,  2. ,  0. ,  2. ,  0. ],\n",
       "          [ 7.1,  0. ,  0. ,  2. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 16. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 17. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 18. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 1.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 2.2, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 2.2, 10. ,  9. ,  2. ,  0. ],\n",
       "          [ 4.1, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.2,  8. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  6. ,  2. ,  0. ],\n",
       "          [ 4.1,  6. ,  6. ,  2. ,  0. ],\n",
       "          [ 5.1,  6. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.1,  6. ,  4. ,  2. ,  0. ],\n",
       "          [ 7.1,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 6.2,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.1,  6. ,  2. ,  2. ,  0. ],\n",
       "          [ 6.2,  4. ,  2. ,  2. ,  0. ],\n",
       "          [ 5.2,  4. ,  1. ,  2. ,  0. ],\n",
       "          [ 5.1,  2. ,  1. ,  2. ,  0. ],\n",
       "          [ 7.2,  2. ,  0. ,  2. ,  0. ],\n",
       "          [ 7.1,  0. ,  0. ,  2. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  2. , 16. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 1.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  8. ,  2. ,  0. ],\n",
       "          [ 5.1, 10. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.2, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 4.2, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 4.1,  8. ,  6. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 7.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.1,  6. ,  3. ,  2. ,  0. ],\n",
       "          [ 2.1,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 6.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 7.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 2.2,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.1,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.2,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 6.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 10. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 1.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 2.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  8. ,  3. ,  0. ],\n",
       "          [ 1.1, 14. ,  8. ,  4. ,  0. ],\n",
       "          [ 3.1, 14. ,  8. ,  4. ,  0. ],\n",
       "          [ 3.2, 12. ,  8. ,  4. ,  0. ],\n",
       "          [ 4.2, 12. ,  7. ,  4. ,  0. ],\n",
       "          [ 1.1, 12. ,  7. ,  5. ,  0. ],\n",
       "          [ 2.2, 12. ,  6. ,  5. ,  0. ],\n",
       "          [ 2.1, 10. ,  6. ,  5. ,  0. ],\n",
       "          [ 5.1, 10. ,  6. ,  5. ,  0. ],\n",
       "          [ 5.2,  8. ,  5. ,  5. ,  0. ],\n",
       "          [ 6.1,  8. ,  4. ,  5. ,  0. ],\n",
       "          [ 1.1,  8. ,  4. ,  6. ,  0. ],\n",
       "          [ 7.1,  8. ,  3. ,  6. ,  0. ],\n",
       "          [ 6.1,  8. ,  3. ,  6. ,  0. ],\n",
       "          [ 4.1,  8. ,  3. ,  6. ,  0. ],\n",
       "          [ 7.1,  8. ,  3. ,  6. ,  0. ],\n",
       "          [ 6.2,  8. ,  2. ,  6. ,  0. ],\n",
       "          [ 1.1,  8. ,  2. ,  7. ,  0. ],\n",
       "          [ 1.2,  8. ,  1. ,  7. ,  0. ],\n",
       "          [ 1.1,  6. ,  1. ,  8. ,  0. ],\n",
       "          [ 4.2,  6. ,  1. ,  8. ,  0. ],\n",
       "          [ 6.1,  6. ,  1. ,  8. ,  0. ],\n",
       "          [ 7.2,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 6.1,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 7.1,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 6.1,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 6.2,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 7.1,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 6.2,  6. ,  0. ,  8. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  8. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 1.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.1, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  7. ,  3. ,  0. ],\n",
       "          [ 6.1, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 7.1, 12. ,  5. ,  3. ,  0. ],\n",
       "          [ 1.1, 12. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.1, 12. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.2, 12. ,  4. ,  3. ,  0. ],\n",
       "          [ 4.1, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 1.2, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 7.2, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 1.1, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 5.1, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 2.1, 10. ,  3. ,  3. ,  0. ],\n",
       "          [ 2.2, 10. ,  2. ,  3. ,  0. ],\n",
       "          [ 2.1,  8. ,  2. ,  4. ,  0. ],\n",
       "          [ 5.2,  8. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.1,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 1.2,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.1,  6. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.1,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 4.2, 14. ,  8. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  7. ,  3. ,  0. ],\n",
       "          [ 6.1, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 2.2, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  5. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. ,  5. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  5. ,  3. ,  0. ],\n",
       "          [ 5.2, 14. ,  4. ,  3. ,  0. ],\n",
       "          [ 1.2, 14. ,  3. ,  3. ,  0. ],\n",
       "          [ 7.1, 14. ,  2. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.1, 12. ,  2. ,  4. ,  0. ],\n",
       "          [ 7.2, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.1, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 1.1, 12. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.2, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 5.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.1, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2, 10. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1, 10. ,  0. ,  4. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 2.2, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 1.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 6.1, 12. ,  7. ,  2. ,  0. ],\n",
       "          [ 3.2, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  6. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  6. ,  2. ,  0. ],\n",
       "          [ 6.2, 10. ,  5. ,  2. ,  0. ],\n",
       "          [ 6.1,  8. ,  5. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 5.1,  8. ,  4. ,  2. ,  0. ],\n",
       "          [ 5.2,  8. ,  3. ,  2. ,  0. ],\n",
       "          [ 5.1,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 7.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 4.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 4.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 4.1,  4. ,  2. ,  3. ,  0. ],\n",
       "          [ 1.2,  4. ,  1. ,  3. ,  0. ],\n",
       "          [ 7.2,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 1.2,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.1,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 7.2,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 11. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 1.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 2.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.1, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 1.2, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.2, 14. ,  8. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  7. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 6.1, 14. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1, 14. ,  4. ,  3. ,  0. ],\n",
       "          [ 6.2, 14. ,  3. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  3. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 3.2, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.2, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 4.2, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 3.2, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 5.2, 14. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 14. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2, 14. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2, 14. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.2, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 7.2, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.1, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 1.1, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 3.1, 14. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.1, 14. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.2, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 3.1, 12. ,  9. ,  2. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  2. ,  0. ],\n",
       "          [ 2.1, 12. ,  8. ,  3. ,  0. ],\n",
       "          [ 6.1, 12. ,  7. ,  3. ,  0. ],\n",
       "          [ 5.2, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 5.2, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 5.1, 10. ,  6. ,  3. ,  0. ],\n",
       "          [ 7.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 6.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.2, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 7.1,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 6.2,  8. ,  3. ,  3. ,  0. ],\n",
       "          [ 6.1,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 1.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 4.2,  6. ,  1. ,  3. ,  0. ],\n",
       "          [ 2.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.1,  6. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.2,  4. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1,  4. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  2. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.2,  2. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.1,  0. ,  0. ,  5. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  5. ,  8. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 1.2, 12. , 12. ,  1. ,  0. ],\n",
       "          [ 2.1, 12. , 11. ,  1. ,  0. ],\n",
       "          [ 3.1, 12. , 10. ,  1. ,  0. ],\n",
       "          [ 4.1, 12. ,  9. ,  1. ,  0. ],\n",
       "          [ 5.1, 12. ,  8. ,  1. ,  0. ],\n",
       "          [ 6.1, 12. ,  7. ,  1. ,  0. ],\n",
       "          [ 6.2, 10. ,  6. ,  1. ,  0. ],\n",
       "          [ 2.2, 10. ,  5. ,  1. ,  0. ],\n",
       "          [ 5.2, 10. ,  4. ,  1. ,  0. ],\n",
       "          [ 4.1, 10. ,  4. ,  2. ,  0. ],\n",
       "          [ 3.2, 10. ,  3. ,  2. ,  0. ],\n",
       "          [ 7.1, 10. ,  2. ,  2. ,  0. ],\n",
       "          [ 7.2,  8. ,  1. ,  2. ,  0. ],\n",
       "          [ 4.2,  8. ,  0. ,  2. ,  0. ],\n",
       "          [ 4.1,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.2,  6. ,  0. ,  3. ,  0. ],\n",
       "          [ 5.1,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.2,  4. ,  0. ,  3. ,  0. ],\n",
       "          [ 2.1,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.1,  2. ,  0. ,  3. ,  0. ],\n",
       "          [ 3.2,  0. ,  0. ,  3. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 14. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 15. ],\n",
       "          [ 0. ,  0. ,  0. ,  3. , 16. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)),\n",
       " (array([[[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  1. ,  0. ],\n",
       "          [ 6.1, 14. ,  8. ,  1. ,  0. ],\n",
       "          [ 7.1, 14. ,  7. ,  1. ,  0. ],\n",
       "          [ 4.2, 14. ,  6. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  6. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 4.2, 12. ,  6. ,  3. ,  0. ],\n",
       "          [ 2.2, 12. ,  5. ,  3. ,  0. ],\n",
       "          [ 2.1, 10. ,  5. ,  3. ,  0. ],\n",
       "          [ 1.2, 10. ,  4. ,  3. ,  0. ],\n",
       "          [ 1.1,  8. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.2,  8. ,  3. ,  3. ,  0. ],\n",
       "          [ 5.1,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 3.1,  6. ,  3. ,  3. ,  0. ],\n",
       "          [ 7.2,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 7.1,  6. ,  2. ,  3. ,  0. ],\n",
       "          [ 7.2,  4. ,  2. ,  3. ,  0. ],\n",
       "          [ 3.2,  4. ,  1. ,  3. ,  0. ],\n",
       "          [ 3.1,  2. ,  1. ,  4. ,  0. ],\n",
       "          [ 6.2,  2. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1,  0. ,  0. ,  4. ,  0. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  1. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  2. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  3. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  4. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  5. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  6. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  7. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  8. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. ,  9. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 10. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 11. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 12. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 13. ],\n",
       "          [ 0. ,  0. ,  0. ,  4. , 14. ]],\n",
       "  \n",
       "         [[ 1.1, 14. , 13. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 12. ,  1. ,  0. ],\n",
       "          [ 3.1, 14. , 11. ,  1. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  1. ,  0. ],\n",
       "          [ 2.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. , 10. ,  2. ,  0. ],\n",
       "          [ 5.1, 14. ,  9. ,  2. ,  0. ],\n",
       "          [ 4.1, 14. ,  9. ,  3. ,  0. ],\n",
       "          [ 6.1, 14. ,  8. ,  3. ,  0. ],\n",
       "          [ 4.2, 14. ,  7. ,  3. ,  0. ],\n",
       "          [ 2.1, 14. ,  7. ,  3. ,  0. ],\n",
       "          [ 4.2, 14. ,  7. ,  3. ,  0. ],\n",
       "          [ 3.2, 14. ,  6. ,  3. ,  0. ],\n",
       "          [ 6.2, 14. ,  5. ,  3. ,  0. ],\n",
       "          [ 7.1, 14. ,  4. ,  3. ,  0. ],\n",
       "          [ 5.1, 14. ,  4. ,  3. ,  0. ],\n",
       "          [ 4.1, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  4. ,  4. ,  0. ],\n",
       "          [ 5.2, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 7.1, 14. ,  3. ,  4. ,  0. ],\n",
       "          [ 2.2, 14. ,  2. ,  4. ,  0. ],\n",
       "          [ 1.2, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 1.1, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 2.2, 14. ,  1. ,  4. ,  0. ],\n",
       "          [ 7.2, 14. ,  0. ,  4. ,  0. ],\n",
       "          [ 7.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 1.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.2, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 6.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.2, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 2.1, 12. ,  0. ,  4. ,  0. ],\n",
       "          [ 4.1, 12. ,  0. ,  5. ,  0. ],\n",
       "          [ 4.2, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 3.2, 10. ,  0. ,  5. ,  0. ],\n",
       "          [ 3.1,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.1,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 6.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 5.2,  8. ,  0. ,  5. ,  0. ],\n",
       "          [ 2.2,  8. ,  0. ,  5. ,  0. ]]]),\n",
       "  array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_splits_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_participants_per_split = 19 # 20 but one is removed in each split for testing\n",
    "simulations_per_participant = 1000\n",
    "n_added_simulations_per_participant = 0\n",
    "n_runs = 1\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_simulated_data(X_train, y_train, simulated_train_set):\n",
    "    for n in range(n_added_simulations_per_participant):\n",
    "        for i in range(n_participants_per_split):\n",
    "\n",
    "            X_train_simulated_1 = simulated_train_set[0][(i * simulations_per_participant) + n]\n",
    "            y_train_simulated_1 = simulated_train_set[1][(i * simulations_per_participant) + n]\n",
    "            X_train_simulated_2 = simulated_train_set[0][(simulations_per_participant * n_participants_per_split) \\\n",
    "                                                         + (i * simulations_per_participant) + n]\n",
    "            y_train_simulated_2 = simulated_train_set[1][(simulations_per_participant * n_participants_per_split) \\\n",
    "                                                         + (i * simulations_per_participant) + n]\n",
    "            \n",
    "            X_train_simulated = np.concatenate((X_train_simulated_1[np.newaxis, :, :], \\\n",
    "                                               X_train_simulated_2[np.newaxis, :, :]), axis=0)\n",
    "            y_train_simulated = np.concatenate((y_train_simulated_1[np.newaxis, :], \\\n",
    "                                               y_train_simulated_2[np.newaxis, :]), axis=0)\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_train_simulated), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_simulated), axis=0)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mean_score_of_run(histories, epochs):\n",
    "    mean_val_losses = []\n",
    "    mean_val_accuracies = []\n",
    "    mean_losses = []\n",
    "    mean_accuracies = []\n",
    "    for i in range(epochs):\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for l in range(len(histories)):\n",
    "            history = histories[l]\n",
    "            val_losses.append(history.history['val_loss'][i])\n",
    "            val_accuracies.append(history.history['val_accuracy'][i])\n",
    "            losses.append(history.history['loss'][i])\n",
    "            accuracies.append(history.history['accuracy'][i])\n",
    "        mean_val_losses.append(np.mean(val_losses))\n",
    "        mean_val_accuracies.append(np.mean(val_accuracies))\n",
    "        mean_losses.append(np.mean(losses))\n",
    "        mean_accuracies.append(np.mean(accuracies))\n",
    "    return mean_val_losses, mean_val_accuracies, mean_losses, mean_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mean_score_over_all_runs(mean_run_scores, n_runs):\n",
    "    val_losses = np.asarray(mean_run_scores[0][0])\n",
    "    val_accuracies = np.asarray(mean_run_scores[0][1])\n",
    "    losses = np.asarray(mean_run_scores[0][2])\n",
    "    accuracies = np.asarray(mean_run_scores[0][3])\n",
    "                            \n",
    "    for i in range(1, n_runs):\n",
    "        val_losses += np.asarray(mean_run_scores[i][0])\n",
    "        val_accuracies += np.asarray(mean_run_scores[i][1])\n",
    "        losses += np.asarray(mean_run_scores[i][2])\n",
    "        accuracies += np.asarray(mean_run_scores[i][3])\n",
    "                                 \n",
    "    val_losses /= n_runs\n",
    "    val_accuracies /= n_runs\n",
    "    losses /= n_runs\n",
    "    accuracies /= n_runs\n",
    "    \n",
    "    return val_losses, val_accuracies, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_and_train(X_train, y_train, X_test, y_test):\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    cnn_input_shape = X_train[0].shape\n",
    "    \n",
    "    #epochs = n_epochs\n",
    "    cnn_batch_size = 32 #1000\n",
    "    #verbose = 0\n",
    "    \n",
    "    #print(cnn_input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=(76, 40,1), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    #model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))#, padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=cnn_batch_size, verbose=1, \n",
    "                        shuffle=True, validation_data=(X_test, y_test))\n",
    "    \n",
    "    #print(history.history['val_accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    histories.append(history)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc52c6dc6c1466094a0a1b0d86ec980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Runs', max=1.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 40)\n",
      "(38, 2)\n",
      "Train on 38 samples, validate on 2 samples\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.6950 - accuracy: 0.4737 - val_loss: 0.6864 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6913 - accuracy: 0.5789 - val_loss: 0.6849 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.6579 - val_loss: 0.6836 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6844 - accuracy: 0.6842 - val_loss: 0.6830 - val_accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6838 - accuracy: 0.6316 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6782 - accuracy: 0.6842 - val_loss: 0.6823 - val_accuracy: 0.5000\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.7105 - val_loss: 0.6822 - val_accuracy: 0.5000\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6738 - accuracy: 0.7632 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6709 - accuracy: 0.7632 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6678 - accuracy: 0.7632 - val_loss: 0.6816 - val_accuracy: 0.5000\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6633 - accuracy: 0.7895 - val_loss: 0.6816 - val_accuracy: 0.5000\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6579 - accuracy: 0.8158 - val_loss: 0.6827 - val_accuracy: 0.5000\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6554 - accuracy: 0.7895 - val_loss: 0.6841 - val_accuracy: 0.5000\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6576 - accuracy: 0.7632 - val_loss: 0.6846 - val_accuracy: 0.5000\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6520 - accuracy: 0.8684 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6526 - accuracy: 0.8421 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6449 - accuracy: 0.8684 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6440 - accuracy: 0.8158 - val_loss: 0.6854 - val_accuracy: 0.5000\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6406 - accuracy: 0.8947 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6317 - accuracy: 0.8421 - val_loss: 0.6838 - val_accuracy: 0.5000\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6340 - accuracy: 0.8421 - val_loss: 0.6836 - val_accuracy: 0.5000\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.8684 - val_loss: 0.6837 - val_accuracy: 0.5000\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.8158 - val_loss: 0.6845 - val_accuracy: 0.5000\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6228 - accuracy: 0.8421 - val_loss: 0.6840 - val_accuracy: 0.5000\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.8684 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6127 - accuracy: 0.8158 - val_loss: 0.6815 - val_accuracy: 0.5000\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6084 - accuracy: 0.8158 - val_loss: 0.6810 - val_accuracy: 0.5000\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6017 - accuracy: 0.8421 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5996 - accuracy: 0.8421 - val_loss: 0.6821 - val_accuracy: 0.5000\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.8421 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5912 - accuracy: 0.8421 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5875 - accuracy: 0.8421 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.8158 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5835 - accuracy: 0.8421 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5787 - accuracy: 0.8421 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5737 - accuracy: 0.8421 - val_loss: 0.6858 - val_accuracy: 0.5000\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5702 - accuracy: 0.8158 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5650 - accuracy: 0.8421 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5619 - accuracy: 0.8421 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.8421 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.8684 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5436 - accuracy: 0.8421 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5425 - accuracy: 0.8421 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5381 - accuracy: 0.8684 - val_loss: 0.7010 - val_accuracy: 0.5000\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.8684 - val_loss: 0.7022 - val_accuracy: 0.5000\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5302 - accuracy: 0.8421 - val_loss: 0.7030 - val_accuracy: 0.5000\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5234 - accuracy: 0.8684 - val_loss: 0.7042 - val_accuracy: 0.5000\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5208 - accuracy: 0.8421 - val_loss: 0.7085 - val_accuracy: 0.5000\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5252 - accuracy: 0.8421 - val_loss: 0.7156 - val_accuracy: 0.5000\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5164 - accuracy: 0.8684 - val_loss: 0.7228 - val_accuracy: 0.5000\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.8684 - val_loss: 0.7289 - val_accuracy: 0.5000\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5145 - accuracy: 0.8421 - val_loss: 0.7317 - val_accuracy: 0.5000\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5130 - accuracy: 0.8684 - val_loss: 0.7314 - val_accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4979 - accuracy: 0.8947 - val_loss: 0.7309 - val_accuracy: 0.5000\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4972 - accuracy: 0.8684 - val_loss: 0.7309 - val_accuracy: 0.5000\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4874 - accuracy: 0.8684 - val_loss: 0.7323 - val_accuracy: 0.5000\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4898 - accuracy: 0.8421 - val_loss: 0.7346 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4813 - accuracy: 0.8684 - val_loss: 0.7399 - val_accuracy: 0.5000\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4789 - accuracy: 0.8684 - val_loss: 0.7466 - val_accuracy: 0.5000\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4730 - accuracy: 0.8684 - val_loss: 0.7525 - val_accuracy: 0.5000\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4750 - accuracy: 0.8947 - val_loss: 0.7570 - val_accuracy: 0.5000\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4616 - accuracy: 0.8684 - val_loss: 0.7588 - val_accuracy: 0.5000\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.8684 - val_loss: 0.7601 - val_accuracy: 0.5000\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.8684 - val_loss: 0.7615 - val_accuracy: 0.5000\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4627 - accuracy: 0.8684 - val_loss: 0.7609 - val_accuracy: 0.5000\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4576 - accuracy: 0.8684 - val_loss: 0.7580 - val_accuracy: 0.5000\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.8684 - val_loss: 0.7530 - val_accuracy: 0.5000\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4462 - accuracy: 0.8684 - val_loss: 0.7489 - val_accuracy: 0.5000\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4537 - accuracy: 0.8158 - val_loss: 0.7483 - val_accuracy: 0.5000\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.8421 - val_loss: 0.7531 - val_accuracy: 0.5000\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4430 - accuracy: 0.8158 - val_loss: 0.7603 - val_accuracy: 0.5000\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4424 - accuracy: 0.8158 - val_loss: 0.7675 - val_accuracy: 0.5000\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4383 - accuracy: 0.8158 - val_loss: 0.7740 - val_accuracy: 0.5000\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4373 - accuracy: 0.8421 - val_loss: 0.7790 - val_accuracy: 0.5000\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4312 - accuracy: 0.8421 - val_loss: 0.7866 - val_accuracy: 0.5000\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.8421 - val_loss: 0.7956 - val_accuracy: 0.5000\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4212 - accuracy: 0.8947 - val_loss: 0.8044 - val_accuracy: 0.5000\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4230 - accuracy: 0.8684 - val_loss: 0.8122 - val_accuracy: 0.5000\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8947 - val_loss: 0.8184 - val_accuracy: 0.5000\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.4183 - accuracy: 0.8947 - val_loss: 0.8227 - val_accuracy: 0.5000\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8947 - val_loss: 0.8263 - val_accuracy: 0.5000\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8947 - val_loss: 0.8285 - val_accuracy: 0.5000\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8947 - val_loss: 0.8305 - val_accuracy: 0.5000\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8947 - val_loss: 0.8330 - val_accuracy: 0.5000\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4046 - accuracy: 0.8684 - val_loss: 0.8355 - val_accuracy: 0.5000\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.4021 - accuracy: 0.8684 - val_loss: 0.8380 - val_accuracy: 0.5000\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3911 - accuracy: 0.8684 - val_loss: 0.8377 - val_accuracy: 0.5000\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3880 - accuracy: 0.8684 - val_loss: 0.8331 - val_accuracy: 0.5000\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8684 - val_loss: 0.8307 - val_accuracy: 0.5000\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3850 - accuracy: 0.8947 - val_loss: 0.8312 - val_accuracy: 0.5000\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8421 - val_loss: 0.8339 - val_accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3821 - accuracy: 0.8684 - val_loss: 0.8356 - val_accuracy: 0.5000\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3790 - accuracy: 0.8684 - val_loss: 0.8386 - val_accuracy: 0.5000\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3735 - accuracy: 0.8947 - val_loss: 0.8478 - val_accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8421 - val_loss: 0.8666 - val_accuracy: 0.5000\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3729 - accuracy: 0.8947 - val_loss: 0.8874 - val_accuracy: 0.5000\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3728 - accuracy: 0.8947 - val_loss: 0.9007 - val_accuracy: 0.5000\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3744 - accuracy: 0.8947 - val_loss: 0.9089 - val_accuracy: 0.5000\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3661 - accuracy: 0.8947 - val_loss: 0.9165 - val_accuracy: 0.5000\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3686 - accuracy: 0.8947 - val_loss: 0.9244 - val_accuracy: 0.5000\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3681 - accuracy: 0.8947 - val_loss: 0.9297 - val_accuracy: 0.5000\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8947 - val_loss: 0.9322 - val_accuracy: 0.5000\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3589 - accuracy: 0.8947 - val_loss: 0.9356 - val_accuracy: 0.5000\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3539 - accuracy: 0.8947 - val_loss: 0.9392 - val_accuracy: 0.5000\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3627 - accuracy: 0.8947 - val_loss: 0.9403 - val_accuracy: 0.5000\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.8947 - val_loss: 0.9438 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3511 - accuracy: 0.8947 - val_loss: 0.9461 - val_accuracy: 0.5000\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3548 - accuracy: 0.8947 - val_loss: 0.9409 - val_accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.3490 - accuracy: 0.8947 - val_loss: 0.9254 - val_accuracy: 0.5000\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3443 - accuracy: 0.8947 - val_loss: 0.9060 - val_accuracy: 0.5000\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3441 - accuracy: 0.8947 - val_loss: 0.8898 - val_accuracy: 0.5000\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.8947 - val_loss: 0.8812 - val_accuracy: 0.5000\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3414 - accuracy: 0.8684 - val_loss: 0.8788 - val_accuracy: 0.5000\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.8947 - val_loss: 0.8818 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3335 - accuracy: 0.8947 - val_loss: 0.8877 - val_accuracy: 0.5000\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8947 - val_loss: 0.8910 - val_accuracy: 0.5000\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.8947 - val_loss: 0.8945 - val_accuracy: 0.5000\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3307 - accuracy: 0.8684 - val_loss: 0.9085 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8947 - val_loss: 0.9290 - val_accuracy: 0.5000\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3165 - accuracy: 0.8947 - val_loss: 0.9541 - val_accuracy: 0.5000\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3170 - accuracy: 0.8947 - val_loss: 0.9764 - val_accuracy: 0.5000\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8947 - val_loss: 0.9880 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3185 - accuracy: 0.8947 - val_loss: 0.9898 - val_accuracy: 0.5000\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3115 - accuracy: 0.9211 - val_loss: 0.9883 - val_accuracy: 0.5000\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3178 - accuracy: 0.8947 - val_loss: 0.9898 - val_accuracy: 0.5000\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.8947 - val_loss: 0.9939 - val_accuracy: 0.5000\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3091 - accuracy: 0.8947 - val_loss: 0.9898 - val_accuracy: 0.5000\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3130 - accuracy: 0.8947 - val_loss: 0.9795 - val_accuracy: 0.5000\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8947 - val_loss: 0.9701 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3143 - accuracy: 0.8947 - val_loss: 0.9629 - val_accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3047 - accuracy: 0.8947 - val_loss: 0.9627 - val_accuracy: 0.5000\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3057 - accuracy: 0.8947 - val_loss: 0.9661 - val_accuracy: 0.5000\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2971 - accuracy: 0.8947 - val_loss: 0.9655 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2909 - accuracy: 0.8947 - val_loss: 0.9665 - val_accuracy: 0.5000\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8947 - val_loss: 0.9763 - val_accuracy: 0.5000\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.9211 - val_loss: 0.9882 - val_accuracy: 0.5000\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2946 - accuracy: 0.8947 - val_loss: 0.9970 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2923 - accuracy: 0.9211 - val_loss: 1.0054 - val_accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2896 - accuracy: 0.8947 - val_loss: 1.0115 - val_accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2875 - accuracy: 0.8947 - val_loss: 1.0126 - val_accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.9211 - val_loss: 1.0180 - val_accuracy: 0.5000\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.8947 - val_loss: 1.0241 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2932 - accuracy: 0.8947 - val_loss: 1.0348 - val_accuracy: 0.5000\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.9211 - val_loss: 1.0411 - val_accuracy: 0.5000\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2779 - accuracy: 0.8947 - val_loss: 1.0385 - val_accuracy: 0.5000\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2799 - accuracy: 0.8947 - val_loss: 1.0366 - val_accuracy: 0.5000\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2809 - accuracy: 0.8947 - val_loss: 1.0294 - val_accuracy: 0.5000\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2814 - accuracy: 0.8947 - val_loss: 1.0199 - val_accuracy: 0.5000\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.8947 - val_loss: 1.0135 - val_accuracy: 0.5000\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2781 - accuracy: 0.8947 - val_loss: 1.0077 - val_accuracy: 0.5000\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2764 - accuracy: 0.9211 - val_loss: 1.0026 - val_accuracy: 0.5000\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2649 - accuracy: 0.9211 - val_loss: 0.9918 - val_accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2664 - accuracy: 0.8947 - val_loss: 0.9777 - val_accuracy: 0.5000\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2764 - accuracy: 0.8684 - val_loss: 0.9741 - val_accuracy: 0.5000\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2719 - accuracy: 0.8947 - val_loss: 0.9740 - val_accuracy: 0.5000\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2673 - accuracy: 0.8947 - val_loss: 0.9704 - val_accuracy: 0.5000\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2659 - accuracy: 0.8947 - val_loss: 0.9772 - val_accuracy: 0.5000\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2622 - accuracy: 0.8947 - val_loss: 0.9872 - val_accuracy: 0.5000\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2646 - accuracy: 0.8947 - val_loss: 0.9980 - val_accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2662 - accuracy: 0.8947 - val_loss: 1.0101 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2627 - accuracy: 0.8947 - val_loss: 1.0181 - val_accuracy: 0.5000\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2581 - accuracy: 0.8947 - val_loss: 1.0279 - val_accuracy: 0.5000\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.8947 - val_loss: 1.0461 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2609 - accuracy: 0.8947 - val_loss: 1.0601 - val_accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2488 - accuracy: 0.9211 - val_loss: 1.0633 - val_accuracy: 0.5000\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2524 - accuracy: 0.9211 - val_loss: 1.0649 - val_accuracy: 0.5000\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2463 - accuracy: 0.9211 - val_loss: 1.0660 - val_accuracy: 0.5000\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.9211 - val_loss: 1.0591 - val_accuracy: 0.5000\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2507 - accuracy: 0.9211 - val_loss: 1.0480 - val_accuracy: 0.5000\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2377 - accuracy: 0.9211 - val_loss: 1.0375 - val_accuracy: 0.5000\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2480 - accuracy: 0.9211 - val_loss: 1.0240 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2370 - accuracy: 0.9211 - val_loss: 1.0096 - val_accuracy: 0.5000\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2475 - accuracy: 0.8947 - val_loss: 0.9965 - val_accuracy: 0.5000\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2400 - accuracy: 0.8947 - val_loss: 0.9873 - val_accuracy: 0.5000\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2442 - accuracy: 0.8947 - val_loss: 0.9756 - val_accuracy: 0.5000\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2358 - accuracy: 0.8947 - val_loss: 0.9765 - val_accuracy: 0.5000\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2424 - accuracy: 0.8947 - val_loss: 0.9883 - val_accuracy: 0.5000\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2332 - accuracy: 0.8947 - val_loss: 1.0053 - val_accuracy: 0.5000\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2340 - accuracy: 0.9211 - val_loss: 1.0235 - val_accuracy: 0.5000\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2273 - accuracy: 0.9211 - val_loss: 1.0361 - val_accuracy: 0.5000\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2324 - accuracy: 0.9211 - val_loss: 1.0395 - val_accuracy: 0.5000\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2305 - accuracy: 0.8947 - val_loss: 1.0345 - val_accuracy: 0.5000\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2314 - accuracy: 0.9211 - val_loss: 1.0226 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2295 - accuracy: 0.9211 - val_loss: 1.0192 - val_accuracy: 0.5000\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2235 - accuracy: 0.9211 - val_loss: 1.0182 - val_accuracy: 0.5000\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2229 - accuracy: 0.9211 - val_loss: 1.0162 - val_accuracy: 0.5000\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2198 - accuracy: 0.8947 - val_loss: 1.0142 - val_accuracy: 0.5000\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2198 - accuracy: 0.9211 - val_loss: 1.0122 - val_accuracy: 0.5000\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2162 - accuracy: 0.9211 - val_loss: 1.0048 - val_accuracy: 0.5000\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2150 - accuracy: 0.9211 - val_loss: 1.0074 - val_accuracy: 0.5000\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2098 - accuracy: 0.8947 - val_loss: 1.0247 - val_accuracy: 0.5000\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2170 - accuracy: 0.9211 - val_loss: 1.0481 - val_accuracy: 0.5000\n",
      "Epoch 193/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2083 - accuracy: 0.9211 - val_loss: 1.0627 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2115 - accuracy: 0.9211 - val_loss: 1.0686 - val_accuracy: 0.5000\n",
      "Epoch 195/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2122 - accuracy: 0.9211 - val_loss: 1.0672 - val_accuracy: 0.5000\n",
      "Epoch 196/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2127 - accuracy: 0.9211 - val_loss: 1.0560 - val_accuracy: 0.5000\n",
      "Epoch 197/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2097 - accuracy: 0.9211 - val_loss: 1.0442 - val_accuracy: 0.5000\n",
      "Epoch 198/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2066 - accuracy: 0.9211 - val_loss: 1.0370 - val_accuracy: 0.5000\n",
      "Epoch 199/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2083 - accuracy: 0.9211 - val_loss: 1.0257 - val_accuracy: 0.5000\n",
      "Epoch 200/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2013 - accuracy: 0.9211 - val_loss: 1.0158 - val_accuracy: 0.5000\n",
      "Epoch 201/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2078 - accuracy: 0.9211 - val_loss: 1.0121 - val_accuracy: 0.5000\n",
      "Epoch 202/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2064 - accuracy: 0.9211 - val_loss: 1.0192 - val_accuracy: 0.5000\n",
      "Epoch 203/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9211 - val_loss: 1.0351 - val_accuracy: 0.5000\n",
      "Epoch 204/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2002 - accuracy: 0.9474 - val_loss: 1.0476 - val_accuracy: 0.5000\n",
      "Epoch 205/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1990 - accuracy: 0.9211 - val_loss: 1.0546 - val_accuracy: 0.5000\n",
      "Epoch 206/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1900 - accuracy: 0.9211 - val_loss: 1.0527 - val_accuracy: 0.5000\n",
      "Epoch 207/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2028 - accuracy: 0.9211 - val_loss: 1.0525 - val_accuracy: 0.5000\n",
      "Epoch 208/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1981 - accuracy: 0.9474 - val_loss: 1.0557 - val_accuracy: 0.5000\n",
      "Epoch 209/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1875 - accuracy: 0.9474 - val_loss: 1.0547 - val_accuracy: 0.5000\n",
      "Epoch 210/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1909 - accuracy: 0.9211 - val_loss: 1.0567 - val_accuracy: 0.5000\n",
      "Epoch 211/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1881 - accuracy: 0.9474 - val_loss: 1.0594 - val_accuracy: 0.5000\n",
      "Epoch 212/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1904 - accuracy: 0.9474 - val_loss: 1.0656 - val_accuracy: 0.5000\n",
      "Epoch 213/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1915 - accuracy: 0.9211 - val_loss: 1.0751 - val_accuracy: 0.5000\n",
      "Epoch 214/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1859 - accuracy: 0.9211 - val_loss: 1.0808 - val_accuracy: 0.5000\n",
      "Epoch 215/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1888 - accuracy: 0.9211 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
      "Epoch 216/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1852 - accuracy: 0.9474 - val_loss: 1.1045 - val_accuracy: 0.5000\n",
      "Epoch 217/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1888 - accuracy: 0.9211 - val_loss: 1.1055 - val_accuracy: 0.5000\n",
      "Epoch 218/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1856 - accuracy: 0.9211 - val_loss: 1.1039 - val_accuracy: 0.5000\n",
      "Epoch 219/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1869 - accuracy: 0.9211 - val_loss: 1.1025 - val_accuracy: 0.5000\n",
      "Epoch 220/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1820 - accuracy: 0.9474 - val_loss: 1.0957 - val_accuracy: 0.5000\n",
      "Epoch 221/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1857 - accuracy: 0.9211 - val_loss: 1.0883 - val_accuracy: 0.5000\n",
      "Epoch 222/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1776 - accuracy: 0.9737 - val_loss: 1.0877 - val_accuracy: 0.5000\n",
      "Epoch 223/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1790 - accuracy: 0.9474 - val_loss: 1.0887 - val_accuracy: 0.5000\n",
      "Epoch 224/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1815 - accuracy: 0.9474 - val_loss: 1.0861 - val_accuracy: 0.5000\n",
      "Epoch 225/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1768 - accuracy: 0.9474 - val_loss: 1.0856 - val_accuracy: 0.5000\n",
      "Epoch 226/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1770 - accuracy: 0.9474 - val_loss: 1.0836 - val_accuracy: 0.5000\n",
      "Epoch 227/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1694 - accuracy: 0.9737 - val_loss: 1.0823 - val_accuracy: 0.5000\n",
      "Epoch 228/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1740 - accuracy: 0.9474 - val_loss: 1.0786 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1771 - accuracy: 0.9474 - val_loss: 1.0696 - val_accuracy: 0.5000\n",
      "Epoch 230/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1760 - accuracy: 0.9474 - val_loss: 1.0730 - val_accuracy: 0.5000\n",
      "Epoch 231/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1702 - accuracy: 0.9737 - val_loss: 1.0780 - val_accuracy: 0.5000\n",
      "Epoch 232/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1677 - accuracy: 0.9474 - val_loss: 1.0778 - val_accuracy: 0.5000\n",
      "Epoch 233/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1675 - accuracy: 0.9474 - val_loss: 1.0777 - val_accuracy: 0.5000\n",
      "Epoch 234/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9737 - val_loss: 1.0827 - val_accuracy: 0.5000\n",
      "Epoch 235/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1718 - accuracy: 0.9474 - val_loss: 1.0786 - val_accuracy: 0.5000\n",
      "Epoch 236/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.9474 - val_loss: 1.0721 - val_accuracy: 0.5000\n",
      "Epoch 237/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.9737 - val_loss: 1.0712 - val_accuracy: 0.5000\n",
      "Epoch 238/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1621 - accuracy: 0.9737 - val_loss: 1.0689 - val_accuracy: 0.5000\n",
      "Epoch 239/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1621 - accuracy: 0.9737 - val_loss: 1.0705 - val_accuracy: 0.5000\n",
      "Epoch 240/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1620 - accuracy: 0.9474 - val_loss: 1.0832 - val_accuracy: 0.5000\n",
      "Epoch 241/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9737 - val_loss: 1.1015 - val_accuracy: 0.5000\n",
      "Epoch 242/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1635 - accuracy: 0.9737 - val_loss: 1.1192 - val_accuracy: 0.5000\n",
      "Epoch 243/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9737 - val_loss: 1.1349 - val_accuracy: 0.5000\n",
      "Epoch 244/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1603 - accuracy: 0.9474 - val_loss: 1.1480 - val_accuracy: 0.5000\n",
      "Epoch 245/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9737 - val_loss: 1.1478 - val_accuracy: 0.5000\n",
      "Epoch 246/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1586 - accuracy: 0.9474 - val_loss: 1.1270 - val_accuracy: 0.5000\n",
      "Epoch 247/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.9737 - val_loss: 1.1057 - val_accuracy: 0.5000\n",
      "Epoch 248/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.9737 - val_loss: 1.0852 - val_accuracy: 0.5000\n",
      "Epoch 249/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.5000\n",
      "Epoch 250/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1500 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.5000\n",
      "Epoch 251/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 1.0000 - val_loss: 1.0273 - val_accuracy: 0.5000\n",
      "Epoch 252/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.5000\n",
      "Epoch 253/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1487 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.5000\n",
      "Epoch 254/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1559 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 0.5000\n",
      "Epoch 255/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1509 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.5000\n",
      "Epoch 256/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 1.1042 - val_accuracy: 0.5000\n",
      "Epoch 257/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1467 - accuracy: 0.9737 - val_loss: 1.1168 - val_accuracy: 0.5000\n",
      "Epoch 258/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.5000\n",
      "Epoch 259/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1403 - accuracy: 1.0000 - val_loss: 1.1472 - val_accuracy: 0.5000\n",
      "Epoch 260/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 0.9737 - val_loss: 1.1597 - val_accuracy: 0.5000\n",
      "Epoch 261/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1520 - accuracy: 0.9474 - val_loss: 1.1665 - val_accuracy: 0.5000\n",
      "Epoch 262/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1348 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.5000\n",
      "Epoch 263/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1498 - accuracy: 0.9737 - val_loss: 1.1649 - val_accuracy: 0.5000\n",
      "Epoch 264/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1438 - accuracy: 0.9737 - val_loss: 1.1537 - val_accuracy: 0.5000\n",
      "Epoch 265/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1409 - accuracy: 0.9737 - val_loss: 1.1458 - val_accuracy: 0.5000\n",
      "Epoch 266/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1402 - accuracy: 0.9737 - val_loss: 1.1413 - val_accuracy: 0.5000\n",
      "Epoch 267/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.5000\n",
      "Epoch 268/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1445 - accuracy: 1.0000 - val_loss: 1.1218 - val_accuracy: 0.5000\n",
      "Epoch 269/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.5000\n",
      "Epoch 270/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1386 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.5000\n",
      "Epoch 271/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 1.0000 - val_loss: 1.0490 - val_accuracy: 0.5000\n",
      "Epoch 272/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 0.5000\n",
      "Epoch 273/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.5000\n",
      "Epoch 274/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1334 - accuracy: 1.0000 - val_loss: 1.0592 - val_accuracy: 0.5000\n",
      "Epoch 275/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 1.0000 - val_loss: 1.0805 - val_accuracy: 0.5000\n",
      "Epoch 276/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.5000\n",
      "Epoch 277/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 1.1213 - val_accuracy: 0.5000\n",
      "Epoch 278/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.5000\n",
      "Epoch 279/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.5000\n",
      "Epoch 280/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.9737 - val_loss: 1.1692 - val_accuracy: 0.5000\n",
      "Epoch 281/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 1.1744 - val_accuracy: 0.5000\n",
      "Epoch 282/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.5000\n",
      "Epoch 283/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 1.1916 - val_accuracy: 0.5000\n",
      "Epoch 284/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 1.2054 - val_accuracy: 0.5000\n",
      "Epoch 285/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1279 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1223 - accuracy: 0.9737 - val_loss: 1.2235 - val_accuracy: 0.5000\n",
      "Epoch 287/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.5000\n",
      "Epoch 288/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 1.2034 - val_accuracy: 0.5000\n",
      "Epoch 289/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 0.9737 - val_loss: 1.1864 - val_accuracy: 0.5000\n",
      "Epoch 290/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 1.1604 - val_accuracy: 0.5000\n",
      "Epoch 291/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1177 - accuracy: 1.0000 - val_loss: 1.1427 - val_accuracy: 0.5000\n",
      "Epoch 292/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.5000\n",
      "Epoch 293/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.5000\n",
      "Epoch 294/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 1.1549 - val_accuracy: 0.5000\n",
      "Epoch 295/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 1.1813 - val_accuracy: 0.5000\n",
      "Epoch 296/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 1.2005 - val_accuracy: 0.5000\n",
      "Epoch 297/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.5000\n",
      "Epoch 298/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 1.2291 - val_accuracy: 0.5000\n",
      "Epoch 299/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1199 - accuracy: 0.9474 - val_loss: 1.2265 - val_accuracy: 0.5000\n",
      "Epoch 300/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.5000\n",
      "Epoch 301/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.5000\n",
      "Epoch 302/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.5000\n",
      "Epoch 303/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.5000\n",
      "Epoch 304/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 1.2367 - val_accuracy: 0.5000\n",
      "Epoch 305/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 1.2484 - val_accuracy: 0.5000\n",
      "Epoch 306/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 1.2550 - val_accuracy: 0.5000\n",
      "Epoch 307/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1197 - accuracy: 1.0000 - val_loss: 1.2695 - val_accuracy: 0.5000\n",
      "Epoch 308/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 0.5000\n",
      "Epoch 309/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.5000\n",
      "Epoch 310/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1177 - accuracy: 0.9737 - val_loss: 1.2419 - val_accuracy: 0.5000\n",
      "Epoch 311/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 1.2398 - val_accuracy: 0.5000\n",
      "Epoch 312/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1091 - accuracy: 0.9737 - val_loss: 1.2345 - val_accuracy: 0.5000\n",
      "Epoch 313/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 1.2237 - val_accuracy: 0.5000\n",
      "Epoch 314/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.5000\n",
      "Epoch 315/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 1.1994 - val_accuracy: 0.5000\n",
      "Epoch 316/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 1.1828 - val_accuracy: 0.5000\n",
      "Epoch 317/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 1.1721 - val_accuracy: 0.5000\n",
      "Epoch 318/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 1.1694 - val_accuracy: 0.5000\n",
      "Epoch 319/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.5000\n",
      "Epoch 320/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.5000\n",
      "Epoch 321/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.5000\n",
      "Epoch 322/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 1.1343 - val_accuracy: 0.5000\n",
      "Epoch 323/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 1.1259 - val_accuracy: 0.5000\n",
      "Epoch 324/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.5000\n",
      "Epoch 325/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.5000\n",
      "Epoch 326/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.5000\n",
      "Epoch 327/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.5000\n",
      "Epoch 328/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.5000\n",
      "Epoch 329/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 1.1961 - val_accuracy: 0.5000\n",
      "Epoch 330/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 1.2307 - val_accuracy: 0.5000\n",
      "Epoch 331/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 1.2634 - val_accuracy: 0.5000\n",
      "Epoch 332/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 1.2831 - val_accuracy: 0.5000\n",
      "Epoch 333/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.5000\n",
      "Epoch 334/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.2733 - val_accuracy: 0.5000\n",
      "Epoch 335/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.5000\n",
      "Epoch 336/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 1.2360 - val_accuracy: 0.5000\n",
      "Epoch 337/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0897 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.5000\n",
      "Epoch 338/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 1.1854 - val_accuracy: 0.5000\n",
      "Epoch 339/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.5000\n",
      "Epoch 340/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 1.1604 - val_accuracy: 0.5000\n",
      "Epoch 341/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 1.1484 - val_accuracy: 0.5000\n",
      "Epoch 342/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 1.1245 - val_accuracy: 0.5000\n",
      "Epoch 344/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 1.1211 - val_accuracy: 0.5000\n",
      "Epoch 345/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.5000\n",
      "Epoch 346/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 0.5000\n",
      "Epoch 347/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 1.1542 - val_accuracy: 0.5000\n",
      "Epoch 348/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 0.5000\n",
      "Epoch 349/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 1.2084 - val_accuracy: 0.5000\n",
      "Epoch 350/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 1.0000 - val_loss: 1.2466 - val_accuracy: 0.5000\n",
      "Epoch 351/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 1.2640 - val_accuracy: 0.5000\n",
      "Epoch 352/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 1.2589 - val_accuracy: 0.5000\n",
      "Epoch 353/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.5000\n",
      "Epoch 354/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 1.2532 - val_accuracy: 0.5000\n",
      "Epoch 355/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 1.2570 - val_accuracy: 0.5000\n",
      "Epoch 356/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 1.2650 - val_accuracy: 0.5000\n",
      "Epoch 357/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.5000\n",
      "Epoch 358/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.5000\n",
      "Epoch 359/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 1.2527 - val_accuracy: 0.5000\n",
      "Epoch 360/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 1.2434 - val_accuracy: 0.5000\n",
      "Epoch 361/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.5000\n",
      "Epoch 362/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.5000\n",
      "Epoch 363/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 1.1994 - val_accuracy: 0.5000\n",
      "Epoch 364/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.5000\n",
      "Epoch 365/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.5000\n",
      "Epoch 366/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.2021 - val_accuracy: 0.5000\n",
      "Epoch 367/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 1.2168 - val_accuracy: 0.5000\n",
      "Epoch 368/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.2309 - val_accuracy: 0.5000\n",
      "Epoch 369/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.5000\n",
      "Epoch 370/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.5000\n",
      "Epoch 371/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.5000\n",
      "Epoch 372/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.5000\n",
      "Epoch 373/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 1.3006 - val_accuracy: 0.5000\n",
      "Epoch 374/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 1.3063 - val_accuracy: 0.5000\n",
      "Epoch 375/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.5000\n",
      "Epoch 376/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 1.3090 - val_accuracy: 0.5000\n",
      "Epoch 377/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 1.3119 - val_accuracy: 0.5000\n",
      "Epoch 378/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.5000\n",
      "Epoch 379/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 1.2963 - val_accuracy: 0.5000\n",
      "Epoch 380/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.2823 - val_accuracy: 0.5000\n",
      "Epoch 381/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 1.2707 - val_accuracy: 0.5000\n",
      "Epoch 382/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 1.2623 - val_accuracy: 0.5000\n",
      "Epoch 383/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.5000\n",
      "Epoch 384/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.5000\n",
      "Epoch 385/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.2385 - val_accuracy: 0.5000\n",
      "Epoch 386/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.5000\n",
      "Epoch 387/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 1.2478 - val_accuracy: 0.5000\n",
      "Epoch 388/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 1.2494 - val_accuracy: 0.5000\n",
      "Epoch 389/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.5000\n",
      "Epoch 390/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.5000\n",
      "Epoch 391/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.5000\n",
      "Epoch 392/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 1.2929 - val_accuracy: 0.5000\n",
      "Epoch 393/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.5000\n",
      "Epoch 394/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 1.3012 - val_accuracy: 0.5000\n",
      "Epoch 395/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 1.3102 - val_accuracy: 0.5000\n",
      "Epoch 396/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 1.3162 - val_accuracy: 0.5000\n",
      "Epoch 397/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 1.3167 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 1.3264 - val_accuracy: 0.5000\n",
      "Epoch 399/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 1.3333 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 1.3225 - val_accuracy: 0.5000\n",
      "Epoch 401/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.5000\n",
      "Epoch 402/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 1.2775 - val_accuracy: 0.5000\n",
      "Epoch 403/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 1.2714 - val_accuracy: 0.5000\n",
      "Epoch 404/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 1.2751 - val_accuracy: 0.5000\n",
      "Epoch 405/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 1.2854 - val_accuracy: 0.5000\n",
      "Epoch 406/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.2989 - val_accuracy: 0.5000\n",
      "Epoch 407/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.5000\n",
      "Epoch 408/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.3239 - val_accuracy: 0.5000\n",
      "Epoch 409/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.5000\n",
      "Epoch 410/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.5000\n",
      "Epoch 411/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 1.3514 - val_accuracy: 0.5000\n",
      "Epoch 412/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 1.3591 - val_accuracy: 0.5000\n",
      "Epoch 413/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 1.3631 - val_accuracy: 0.5000\n",
      "Epoch 414/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 1.3541 - val_accuracy: 0.5000\n",
      "Epoch 415/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 1.3265 - val_accuracy: 0.5000\n",
      "Epoch 416/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 1.2819 - val_accuracy: 0.5000\n",
      "Epoch 417/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 1.2407 - val_accuracy: 0.5000\n",
      "Epoch 418/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 1.1980 - val_accuracy: 0.5000\n",
      "Epoch 419/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 1.1590 - val_accuracy: 0.5000\n",
      "Epoch 420/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 1.1403 - val_accuracy: 0.5000\n",
      "Epoch 421/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 1.1373 - val_accuracy: 0.5000\n",
      "Epoch 422/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 1.1386 - val_accuracy: 0.5000\n",
      "Epoch 423/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.5000\n",
      "Epoch 424/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 1.1616 - val_accuracy: 0.5000\n",
      "Epoch 425/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.5000\n",
      "Epoch 426/1000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.5000\n",
      "Epoch 427/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.5000\n",
      "Epoch 428/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.5000\n",
      "Epoch 429/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.3431 - val_accuracy: 0.5000\n",
      "Epoch 430/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 1.3579 - val_accuracy: 0.5000\n",
      "Epoch 431/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.5000\n",
      "Epoch 432/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 1.3916 - val_accuracy: 0.5000\n",
      "Epoch 433/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 1.4034 - val_accuracy: 0.5000\n",
      "Epoch 434/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.5000\n",
      "Epoch 435/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.3909 - val_accuracy: 0.5000\n",
      "Epoch 436/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 1.3821 - val_accuracy: 0.5000\n",
      "Epoch 437/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 1.3693 - val_accuracy: 0.5000\n",
      "Epoch 438/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.5000\n",
      "Epoch 439/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.5000\n",
      "Epoch 440/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 1.2931 - val_accuracy: 0.5000\n",
      "Epoch 441/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 1.2669 - val_accuracy: 0.5000\n",
      "Epoch 442/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 1.2468 - val_accuracy: 0.5000\n",
      "Epoch 443/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.5000\n",
      "Epoch 444/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.5000\n",
      "Epoch 445/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.5000\n",
      "Epoch 446/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 1.2170 - val_accuracy: 0.5000\n",
      "Epoch 447/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 1.2329 - val_accuracy: 0.5000\n",
      "Epoch 448/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 1.2618 - val_accuracy: 0.5000\n",
      "Epoch 449/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.2895 - val_accuracy: 0.5000\n",
      "Epoch 450/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.3200 - val_accuracy: 0.5000\n",
      "Epoch 451/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.3537 - val_accuracy: 0.5000\n",
      "Epoch 452/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.5000\n",
      "Epoch 453/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 1.4351 - val_accuracy: 0.5000\n",
      "Epoch 454/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 1.4668 - val_accuracy: 0.5000\n",
      "Epoch 455/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.5000\n",
      "Epoch 456/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 1.4839 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.4805 - val_accuracy: 0.5000\n",
      "Epoch 458/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.5000\n",
      "Epoch 459/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.5000\n",
      "Epoch 460/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.5000\n",
      "Epoch 461/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 1.2964 - val_accuracy: 0.5000\n",
      "Epoch 462/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.5000\n",
      "Epoch 463/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.5000\n",
      "Epoch 464/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.2058 - val_accuracy: 0.5000\n",
      "Epoch 465/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.5000\n",
      "Epoch 466/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.2305 - val_accuracy: 0.5000\n",
      "Epoch 467/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 1.2616 - val_accuracy: 0.5000\n",
      "Epoch 468/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 1.3004 - val_accuracy: 0.5000\n",
      "Epoch 469/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.5000\n",
      "Epoch 470/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 1.3345 - val_accuracy: 0.5000\n",
      "Epoch 471/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 1.3362 - val_accuracy: 0.5000\n",
      "Epoch 472/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 1.3326 - val_accuracy: 0.5000\n",
      "Epoch 473/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.5000\n",
      "Epoch 474/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.5000\n",
      "Epoch 475/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.3149 - val_accuracy: 0.5000\n",
      "Epoch 476/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.5000\n",
      "Epoch 477/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.3120 - val_accuracy: 0.5000\n",
      "Epoch 478/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.5000\n",
      "Epoch 479/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 1.3027 - val_accuracy: 0.5000\n",
      "Epoch 480/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.5000\n",
      "Epoch 481/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.5000\n",
      "Epoch 482/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 1.2967 - val_accuracy: 0.5000\n",
      "Epoch 483/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.3022 - val_accuracy: 0.5000\n",
      "Epoch 484/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.5000\n",
      "Epoch 485/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 1.3043 - val_accuracy: 0.5000\n",
      "Epoch 486/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 1.3066 - val_accuracy: 0.5000\n",
      "Epoch 487/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.3062 - val_accuracy: 0.5000\n",
      "Epoch 488/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.3106 - val_accuracy: 0.5000\n",
      "Epoch 489/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.5000\n",
      "Epoch 490/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.5000\n",
      "Epoch 491/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.3714 - val_accuracy: 0.5000\n",
      "Epoch 492/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.5000\n",
      "Epoch 493/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.5000\n",
      "Epoch 494/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.5000\n",
      "Epoch 495/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 1.4035 - val_accuracy: 0.5000\n",
      "Epoch 496/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.4090 - val_accuracy: 0.5000\n",
      "Epoch 497/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.4091 - val_accuracy: 0.5000\n",
      "Epoch 498/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 1.3983 - val_accuracy: 0.5000\n",
      "Epoch 499/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.3688 - val_accuracy: 0.5000\n",
      "Epoch 500/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.3373 - val_accuracy: 0.5000\n",
      "Epoch 501/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.5000\n",
      "Epoch 502/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.5000\n",
      "Epoch 503/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.5000\n",
      "Epoch 504/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 1.2920 - val_accuracy: 0.5000\n",
      "Epoch 505/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.2842 - val_accuracy: 0.5000\n",
      "Epoch 506/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.2777 - val_accuracy: 0.5000\n",
      "Epoch 507/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.5000\n",
      "Epoch 508/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.5000\n",
      "Epoch 509/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.2903 - val_accuracy: 0.5000\n",
      "Epoch 510/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.3104 - val_accuracy: 0.5000\n",
      "Epoch 511/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 1.3269 - val_accuracy: 0.5000\n",
      "Epoch 512/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.3342 - val_accuracy: 0.5000\n",
      "Epoch 513/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.3392 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.3544 - val_accuracy: 0.5000\n",
      "Epoch 515/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.3663 - val_accuracy: 0.5000\n",
      "Epoch 516/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.3685 - val_accuracy: 0.5000\n",
      "Epoch 517/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.3700 - val_accuracy: 0.5000\n",
      "Epoch 518/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.5000\n",
      "Epoch 519/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.3614 - val_accuracy: 0.5000\n",
      "Epoch 520/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 521/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.5000\n",
      "Epoch 522/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 1.3422 - val_accuracy: 0.5000\n",
      "Epoch 523/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.3222 - val_accuracy: 0.5000\n",
      "Epoch 524/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.5000\n",
      "Epoch 525/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.5000\n",
      "Epoch 526/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 1.2798 - val_accuracy: 0.5000\n",
      "Epoch 527/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.5000\n",
      "Epoch 528/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.5000\n",
      "Epoch 529/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 1.3550 - val_accuracy: 0.5000\n",
      "Epoch 530/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.5000\n",
      "Epoch 531/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.4393 - val_accuracy: 0.5000\n",
      "Epoch 532/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.4687 - val_accuracy: 0.5000\n",
      "Epoch 533/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.4859 - val_accuracy: 0.5000\n",
      "Epoch 534/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.4908 - val_accuracy: 0.5000\n",
      "Epoch 535/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.4889 - val_accuracy: 0.5000\n",
      "Epoch 536/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.4873 - val_accuracy: 0.5000\n",
      "Epoch 537/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.4990 - val_accuracy: 0.5000\n",
      "Epoch 538/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.5189 - val_accuracy: 0.5000\n",
      "Epoch 539/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.5272 - val_accuracy: 0.5000\n",
      "Epoch 540/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.5234 - val_accuracy: 0.5000\n",
      "Epoch 541/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.5156 - val_accuracy: 0.5000\n",
      "Epoch 542/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.5000\n",
      "Epoch 543/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.5035 - val_accuracy: 0.5000\n",
      "Epoch 544/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.4932 - val_accuracy: 0.5000\n",
      "Epoch 545/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.4720 - val_accuracy: 0.5000\n",
      "Epoch 546/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.4562 - val_accuracy: 0.5000\n",
      "Epoch 547/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.4434 - val_accuracy: 0.5000\n",
      "Epoch 548/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.5000\n",
      "Epoch 549/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.3908 - val_accuracy: 0.5000\n",
      "Epoch 550/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.3797 - val_accuracy: 0.5000\n",
      "Epoch 551/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.3805 - val_accuracy: 0.5000\n",
      "Epoch 552/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.3840 - val_accuracy: 0.5000\n",
      "Epoch 553/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.5000\n",
      "Epoch 554/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.3931 - val_accuracy: 0.5000\n",
      "Epoch 555/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.3922 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.3950 - val_accuracy: 0.5000\n",
      "Epoch 557/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.5000\n",
      "Epoch 558/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.3882 - val_accuracy: 0.5000\n",
      "Epoch 559/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.3853 - val_accuracy: 0.5000\n",
      "Epoch 560/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.3883 - val_accuracy: 0.5000\n",
      "Epoch 561/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.3852 - val_accuracy: 0.5000\n",
      "Epoch 562/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.3818 - val_accuracy: 0.5000\n",
      "Epoch 563/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.5000\n",
      "Epoch 564/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.5000\n",
      "Epoch 565/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.4073 - val_accuracy: 0.5000\n",
      "Epoch 566/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.4157 - val_accuracy: 0.5000\n",
      "Epoch 567/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.4308 - val_accuracy: 0.5000\n",
      "Epoch 568/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.4480 - val_accuracy: 0.5000\n",
      "Epoch 569/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.5000\n",
      "Epoch 570/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.4589 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.4607 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.4629 - val_accuracy: 0.5000\n",
      "Epoch 573/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.4682 - val_accuracy: 0.5000\n",
      "Epoch 574/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.4851 - val_accuracy: 0.5000\n",
      "Epoch 575/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.5074 - val_accuracy: 0.5000\n",
      "Epoch 576/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.5296 - val_accuracy: 0.5000\n",
      "Epoch 577/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.5000\n",
      "Epoch 578/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.5499 - val_accuracy: 0.5000\n",
      "Epoch 579/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.5000\n",
      "Epoch 580/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.5238 - val_accuracy: 0.5000\n",
      "Epoch 582/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.5164 - val_accuracy: 0.5000\n",
      "Epoch 583/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.5117 - val_accuracy: 0.5000\n",
      "Epoch 584/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.5052 - val_accuracy: 0.5000\n",
      "Epoch 585/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.5000\n",
      "Epoch 586/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.4782 - val_accuracy: 0.5000\n",
      "Epoch 587/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.4440 - val_accuracy: 0.5000\n",
      "Epoch 588/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.5000\n",
      "Epoch 589/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.4079 - val_accuracy: 0.5000\n",
      "Epoch 590/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.4090 - val_accuracy: 0.5000\n",
      "Epoch 591/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.4087 - val_accuracy: 0.5000\n",
      "Epoch 592/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.5000\n",
      "Epoch 593/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.4081 - val_accuracy: 0.5000\n",
      "Epoch 594/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.4037 - val_accuracy: 0.5000\n",
      "Epoch 595/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.4116 - val_accuracy: 0.5000\n",
      "Epoch 596/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.5000\n",
      "Epoch 597/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.4451 - val_accuracy: 0.5000\n",
      "Epoch 598/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.4672 - val_accuracy: 0.5000\n",
      "Epoch 599/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.4835 - val_accuracy: 0.5000\n",
      "Epoch 600/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.5010 - val_accuracy: 0.5000\n",
      "Epoch 601/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.5178 - val_accuracy: 0.5000\n",
      "Epoch 602/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.5222 - val_accuracy: 0.5000\n",
      "Epoch 603/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.5136 - val_accuracy: 0.5000\n",
      "Epoch 604/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.5000\n",
      "Epoch 605/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.4928 - val_accuracy: 0.5000\n",
      "Epoch 606/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.4850 - val_accuracy: 0.5000\n",
      "Epoch 607/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.5000\n",
      "Epoch 608/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.5000\n",
      "Epoch 609/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.4903 - val_accuracy: 0.5000\n",
      "Epoch 610/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.5000\n",
      "Epoch 611/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.4554 - val_accuracy: 0.5000\n",
      "Epoch 612/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 0.5000\n",
      "Epoch 613/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.4054 - val_accuracy: 0.5000\n",
      "Epoch 614/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.3993 - val_accuracy: 0.5000\n",
      "Epoch 615/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.5000\n",
      "Epoch 616/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.5000\n",
      "Epoch 617/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.4312 - val_accuracy: 0.5000\n",
      "Epoch 618/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.4341 - val_accuracy: 0.5000\n",
      "Epoch 619/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.4396 - val_accuracy: 0.5000\n",
      "Epoch 620/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.4533 - val_accuracy: 0.5000\n",
      "Epoch 621/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.4725 - val_accuracy: 0.5000\n",
      "Epoch 622/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.4790 - val_accuracy: 0.5000\n",
      "Epoch 623/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.4724 - val_accuracy: 0.5000\n",
      "Epoch 624/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.5000\n",
      "Epoch 625/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.4723 - val_accuracy: 0.5000\n",
      "Epoch 626/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.4707 - val_accuracy: 0.5000\n",
      "Epoch 627/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.4609 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.5000\n",
      "Epoch 629/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.4434 - val_accuracy: 0.5000\n",
      "Epoch 630/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.4465 - val_accuracy: 0.5000\n",
      "Epoch 631/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.4507 - val_accuracy: 0.5000\n",
      "Epoch 632/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.4482 - val_accuracy: 0.5000\n",
      "Epoch 633/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.4421 - val_accuracy: 0.5000\n",
      "Epoch 634/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.4410 - val_accuracy: 0.5000\n",
      "Epoch 635/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.5000\n",
      "Epoch 636/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.4581 - val_accuracy: 0.5000\n",
      "Epoch 637/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.4648 - val_accuracy: 0.5000\n",
      "Epoch 638/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.4710 - val_accuracy: 0.5000\n",
      "Epoch 639/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.5000\n",
      "Epoch 640/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.5046 - val_accuracy: 0.5000\n",
      "Epoch 641/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.5312 - val_accuracy: 0.5000\n",
      "Epoch 642/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.5562 - val_accuracy: 0.5000\n",
      "Epoch 643/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.5719 - val_accuracy: 0.5000\n",
      "Epoch 644/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.5744 - val_accuracy: 0.5000\n",
      "Epoch 645/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.5000\n",
      "Epoch 646/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.5439 - val_accuracy: 0.5000\n",
      "Epoch 647/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.5161 - val_accuracy: 0.5000\n",
      "Epoch 648/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.4799 - val_accuracy: 0.5000\n",
      "Epoch 649/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.4405 - val_accuracy: 0.5000\n",
      "Epoch 650/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.4084 - val_accuracy: 0.5000\n",
      "Epoch 651/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.5000\n",
      "Epoch 652/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.5000\n",
      "Epoch 653/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.4413 - val_accuracy: 0.5000\n",
      "Epoch 654/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.4607 - val_accuracy: 0.5000\n",
      "Epoch 655/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.4776 - val_accuracy: 0.5000\n",
      "Epoch 656/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.5000\n",
      "Epoch 657/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.5036 - val_accuracy: 0.5000\n",
      "Epoch 658/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.5000 - val_accuracy: 0.5000\n",
      "Epoch 659/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.5004 - val_accuracy: 0.5000\n",
      "Epoch 660/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.5000\n",
      "Epoch 661/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.4807 - val_accuracy: 0.5000\n",
      "Epoch 662/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.4710 - val_accuracy: 0.5000\n",
      "Epoch 663/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.4674 - val_accuracy: 0.5000\n",
      "Epoch 664/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.4626 - val_accuracy: 0.5000\n",
      "Epoch 665/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.4664 - val_accuracy: 0.5000\n",
      "Epoch 666/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.5000\n",
      "Epoch 667/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.4646 - val_accuracy: 0.5000\n",
      "Epoch 668/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.5000\n",
      "Epoch 669/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.4757 - val_accuracy: 0.5000\n",
      "Epoch 670/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.4943 - val_accuracy: 0.5000\n",
      "Epoch 671/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.5200 - val_accuracy: 0.5000\n",
      "Epoch 672/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.5322 - val_accuracy: 0.5000\n",
      "Epoch 673/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.5349 - val_accuracy: 0.5000\n",
      "Epoch 674/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.5434 - val_accuracy: 0.5000\n",
      "Epoch 675/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.5530 - val_accuracy: 0.5000\n",
      "Epoch 676/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.5679 - val_accuracy: 0.5000\n",
      "Epoch 677/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.5000\n",
      "Epoch 678/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.6044 - val_accuracy: 0.5000\n",
      "Epoch 679/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.6203 - val_accuracy: 0.5000\n",
      "Epoch 680/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.6286 - val_accuracy: 0.5000\n",
      "Epoch 681/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.6354 - val_accuracy: 0.5000\n",
      "Epoch 682/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.6377 - val_accuracy: 0.5000\n",
      "Epoch 683/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.6397 - val_accuracy: 0.5000\n",
      "Epoch 684/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.6426 - val_accuracy: 0.5000\n",
      "Epoch 686/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.6426 - val_accuracy: 0.5000\n",
      "Epoch 687/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.6322 - val_accuracy: 0.5000\n",
      "Epoch 688/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.5000\n",
      "Epoch 689/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.5000\n",
      "Epoch 690/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.5548 - val_accuracy: 0.5000\n",
      "Epoch 691/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.5367 - val_accuracy: 0.5000\n",
      "Epoch 692/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.5288 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.5259 - val_accuracy: 0.5000\n",
      "Epoch 694/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.5279 - val_accuracy: 0.5000\n",
      "Epoch 695/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.5268 - val_accuracy: 0.5000\n",
      "Epoch 696/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.5232 - val_accuracy: 0.5000\n",
      "Epoch 697/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.5282 - val_accuracy: 0.5000\n",
      "Epoch 698/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.5000\n",
      "Epoch 699/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.5357 - val_accuracy: 0.5000\n",
      "Epoch 700/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.5353 - val_accuracy: 0.5000\n",
      "Epoch 701/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.5253 - val_accuracy: 0.5000\n",
      "Epoch 702/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.5000\n",
      "Epoch 703/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.4955 - val_accuracy: 0.5000\n",
      "Epoch 704/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.4974 - val_accuracy: 0.5000\n",
      "Epoch 705/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.5063 - val_accuracy: 0.5000\n",
      "Epoch 706/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.5148 - val_accuracy: 0.5000\n",
      "Epoch 707/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.5000\n",
      "Epoch 708/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.5361 - val_accuracy: 0.5000\n",
      "Epoch 709/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.5479 - val_accuracy: 0.5000\n",
      "Epoch 710/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.5548 - val_accuracy: 0.5000\n",
      "Epoch 711/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.5613 - val_accuracy: 0.5000\n",
      "Epoch 712/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.5671 - val_accuracy: 0.5000\n",
      "Epoch 713/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.5767 - val_accuracy: 0.5000\n",
      "Epoch 714/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.5922 - val_accuracy: 0.5000\n",
      "Epoch 715/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.6072 - val_accuracy: 0.5000\n",
      "Epoch 716/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.6124 - val_accuracy: 0.5000\n",
      "Epoch 717/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.6193 - val_accuracy: 0.5000\n",
      "Epoch 718/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.5000\n",
      "Epoch 719/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.6314 - val_accuracy: 0.5000\n",
      "Epoch 720/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.6395 - val_accuracy: 0.5000\n",
      "Epoch 721/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.6430 - val_accuracy: 0.5000\n",
      "Epoch 722/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.6346 - val_accuracy: 0.5000\n",
      "Epoch 723/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.6219 - val_accuracy: 0.5000\n",
      "Epoch 724/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.6165 - val_accuracy: 0.5000\n",
      "Epoch 725/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.6119 - val_accuracy: 0.5000\n",
      "Epoch 726/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.6024 - val_accuracy: 0.5000\n",
      "Epoch 727/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.5949 - val_accuracy: 0.5000\n",
      "Epoch 728/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.5820 - val_accuracy: 0.5000\n",
      "Epoch 729/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.5634 - val_accuracy: 0.5000\n",
      "Epoch 730/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.5451 - val_accuracy: 0.5000\n",
      "Epoch 731/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.5336 - val_accuracy: 0.5000\n",
      "Epoch 732/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5226 - val_accuracy: 0.5000\n",
      "Epoch 733/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.5000\n",
      "Epoch 734/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.5198 - val_accuracy: 0.5000\n",
      "Epoch 735/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.5210 - val_accuracy: 0.5000\n",
      "Epoch 736/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.5239 - val_accuracy: 0.5000\n",
      "Epoch 737/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.5344 - val_accuracy: 0.5000\n",
      "Epoch 738/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.5000\n",
      "Epoch 739/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.5628 - val_accuracy: 0.5000\n",
      "Epoch 740/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.5730 - val_accuracy: 0.5000\n",
      "Epoch 741/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.5812 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.5912 - val_accuracy: 0.5000\n",
      "Epoch 743/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.5992 - val_accuracy: 0.5000\n",
      "Epoch 744/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.6110 - val_accuracy: 0.5000\n",
      "Epoch 745/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.6204 - val_accuracy: 0.5000\n",
      "Epoch 746/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.5000\n",
      "Epoch 747/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.5982 - val_accuracy: 0.5000\n",
      "Epoch 748/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.5853 - val_accuracy: 0.5000\n",
      "Epoch 749/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.5000\n",
      "Epoch 750/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.5735 - val_accuracy: 0.5000\n",
      "Epoch 751/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.5699 - val_accuracy: 0.5000\n",
      "Epoch 752/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.5669 - val_accuracy: 0.5000\n",
      "Epoch 753/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.5623 - val_accuracy: 0.5000\n",
      "Epoch 754/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.5648 - val_accuracy: 0.5000\n",
      "Epoch 755/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.5719 - val_accuracy: 0.5000\n",
      "Epoch 756/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.5749 - val_accuracy: 0.5000\n",
      "Epoch 757/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.5760 - val_accuracy: 0.5000\n",
      "Epoch 758/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.5731 - val_accuracy: 0.5000\n",
      "Epoch 759/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.5667 - val_accuracy: 0.5000\n",
      "Epoch 760/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.5654 - val_accuracy: 0.5000\n",
      "Epoch 761/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.5000\n",
      "Epoch 762/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.5733 - val_accuracy: 0.5000\n",
      "Epoch 763/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.5000\n",
      "Epoch 764/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5974 - val_accuracy: 0.5000\n",
      "Epoch 765/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.6128 - val_accuracy: 0.5000\n",
      "Epoch 766/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.6335 - val_accuracy: 0.5000\n",
      "Epoch 767/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.6473 - val_accuracy: 0.5000\n",
      "Epoch 768/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.6503 - val_accuracy: 0.5000\n",
      "Epoch 769/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.6510 - val_accuracy: 0.5000\n",
      "Epoch 770/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.6549 - val_accuracy: 0.5000\n",
      "Epoch 771/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.5000\n",
      "Epoch 772/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.6779 - val_accuracy: 0.5000\n",
      "Epoch 773/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.6850 - val_accuracy: 0.5000\n",
      "Epoch 774/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.6860 - val_accuracy: 0.5000\n",
      "Epoch 775/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6830 - val_accuracy: 0.5000\n",
      "Epoch 776/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.6724 - val_accuracy: 0.5000\n",
      "Epoch 777/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.6653 - val_accuracy: 0.5000\n",
      "Epoch 778/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6640 - val_accuracy: 0.5000\n",
      "Epoch 779/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.6607 - val_accuracy: 0.5000\n",
      "Epoch 780/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.5000\n",
      "Epoch 781/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.6386 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.6374 - val_accuracy: 0.5000\n",
      "Epoch 783/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6388 - val_accuracy: 0.5000\n",
      "Epoch 784/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.6421 - val_accuracy: 0.5000\n",
      "Epoch 785/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.5000\n",
      "Epoch 786/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6508 - val_accuracy: 0.5000\n",
      "Epoch 787/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.5000\n",
      "Epoch 788/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.5000\n",
      "Epoch 789/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.6602 - val_accuracy: 0.5000\n",
      "Epoch 790/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.6550 - val_accuracy: 0.5000\n",
      "Epoch 791/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.5000\n",
      "Epoch 792/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.6197 - val_accuracy: 0.5000\n",
      "Epoch 793/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.5000\n",
      "Epoch 794/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.5000\n",
      "Epoch 795/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.5631 - val_accuracy: 0.5000\n",
      "Epoch 796/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.5000\n",
      "Epoch 797/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.5000\n",
      "Epoch 798/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5523 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.5587 - val_accuracy: 0.5000\n",
      "Epoch 800/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5717 - val_accuracy: 0.5000\n",
      "Epoch 801/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.5915 - val_accuracy: 0.5000\n",
      "Epoch 802/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6173 - val_accuracy: 0.5000\n",
      "Epoch 803/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.5000\n",
      "Epoch 804/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.6582 - val_accuracy: 0.5000\n",
      "Epoch 805/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.6782 - val_accuracy: 0.5000\n",
      "Epoch 806/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.6943 - val_accuracy: 0.5000\n",
      "Epoch 807/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.7053 - val_accuracy: 0.5000\n",
      "Epoch 808/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.7108 - val_accuracy: 0.5000\n",
      "Epoch 809/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.5000\n",
      "Epoch 810/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.5000\n",
      "Epoch 811/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.7133 - val_accuracy: 0.5000\n",
      "Epoch 812/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.7180 - val_accuracy: 0.5000\n",
      "Epoch 813/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.7241 - val_accuracy: 0.5000\n",
      "Epoch 814/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.7239 - val_accuracy: 0.5000\n",
      "Epoch 815/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.7180 - val_accuracy: 0.5000\n",
      "Epoch 816/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7091 - val_accuracy: 0.5000\n",
      "Epoch 817/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6904 - val_accuracy: 0.5000\n",
      "Epoch 818/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.6683 - val_accuracy: 0.5000\n",
      "Epoch 819/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.5000\n",
      "Epoch 820/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.6023 - val_accuracy: 0.5000\n",
      "Epoch 821/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5673 - val_accuracy: 0.5000\n",
      "Epoch 822/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5500 - val_accuracy: 0.5000\n",
      "Epoch 823/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.5000\n",
      "Epoch 824/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5376 - val_accuracy: 0.5000\n",
      "Epoch 825/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5395 - val_accuracy: 0.5000\n",
      "Epoch 826/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.5000\n",
      "Epoch 827/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.5798 - val_accuracy: 0.5000\n",
      "Epoch 828/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.6022 - val_accuracy: 0.5000\n",
      "Epoch 829/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.5000\n",
      "Epoch 830/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6298 - val_accuracy: 0.5000\n",
      "Epoch 831/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.6412 - val_accuracy: 0.5000\n",
      "Epoch 832/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6544 - val_accuracy: 0.5000\n",
      "Epoch 833/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.5000\n",
      "Epoch 834/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6656 - val_accuracy: 0.5000\n",
      "Epoch 835/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.6580 - val_accuracy: 0.5000\n",
      "Epoch 836/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.5000\n",
      "Epoch 837/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.6482 - val_accuracy: 0.5000\n",
      "Epoch 838/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6511 - val_accuracy: 0.5000\n",
      "Epoch 839/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.5000\n",
      "Epoch 840/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.6974 - val_accuracy: 0.5000\n",
      "Epoch 841/1000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7197 - val_accuracy: 0.5000\n",
      "Epoch 842/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.7346 - val_accuracy: 0.5000\n",
      "Epoch 843/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.5000\n",
      "Epoch 844/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.7453 - val_accuracy: 0.5000\n",
      "Epoch 845/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.7442 - val_accuracy: 0.5000\n",
      "Epoch 846/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.7326 - val_accuracy: 0.5000\n",
      "Epoch 847/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.7112 - val_accuracy: 0.5000\n",
      "Epoch 848/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6881 - val_accuracy: 0.5000\n",
      "Epoch 849/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6716 - val_accuracy: 0.5000\n",
      "Epoch 850/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.6588 - val_accuracy: 0.5000\n",
      "Epoch 851/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6495 - val_accuracy: 0.5000\n",
      "Epoch 852/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.5000\n",
      "Epoch 853/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6266 - val_accuracy: 0.5000\n",
      "Epoch 854/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6157 - val_accuracy: 0.5000\n",
      "Epoch 855/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.6076 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6015 - val_accuracy: 0.5000\n",
      "Epoch 857/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.5000\n",
      "Epoch 858/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5947 - val_accuracy: 0.5000\n",
      "Epoch 859/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.5000\n",
      "Epoch 860/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6087 - val_accuracy: 0.5000\n",
      "Epoch 861/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6181 - val_accuracy: 0.5000\n",
      "Epoch 862/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6229 - val_accuracy: 0.5000\n",
      "Epoch 863/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.6150 - val_accuracy: 0.5000\n",
      "Epoch 864/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6070 - val_accuracy: 0.5000\n",
      "Epoch 865/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6119 - val_accuracy: 0.5000\n",
      "Epoch 866/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.6239 - val_accuracy: 0.5000\n",
      "Epoch 867/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.6371 - val_accuracy: 0.5000\n",
      "Epoch 868/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6521 - val_accuracy: 0.5000\n",
      "Epoch 869/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.5000\n",
      "Epoch 870/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6857 - val_accuracy: 0.5000\n",
      "Epoch 871/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.7013 - val_accuracy: 0.5000\n",
      "Epoch 872/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.5000\n",
      "Epoch 873/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.7359 - val_accuracy: 0.5000\n",
      "Epoch 874/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7492 - val_accuracy: 0.5000\n",
      "Epoch 875/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.7499 - val_accuracy: 0.5000\n",
      "Epoch 876/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7373 - val_accuracy: 0.5000\n",
      "Epoch 877/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.7174 - val_accuracy: 0.5000\n",
      "Epoch 878/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.6871 - val_accuracy: 0.5000\n",
      "Epoch 879/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.5000\n",
      "Epoch 880/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.6223 - val_accuracy: 0.5000\n",
      "Epoch 881/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5996 - val_accuracy: 0.5000\n",
      "Epoch 882/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5818 - val_accuracy: 0.5000\n",
      "Epoch 883/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.5760 - val_accuracy: 0.5000\n",
      "Epoch 884/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.5000\n",
      "Epoch 885/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5724 - val_accuracy: 0.5000\n",
      "Epoch 886/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5770 - val_accuracy: 0.5000\n",
      "Epoch 887/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.5821 - val_accuracy: 0.5000\n",
      "Epoch 888/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5889 - val_accuracy: 0.5000\n",
      "Epoch 889/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6040 - val_accuracy: 0.5000\n",
      "Epoch 890/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6268 - val_accuracy: 0.5000\n",
      "Epoch 891/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6419 - val_accuracy: 0.5000\n",
      "Epoch 892/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.6576 - val_accuracy: 0.5000\n",
      "Epoch 893/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6767 - val_accuracy: 0.5000\n",
      "Epoch 894/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.5000\n",
      "Epoch 895/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.7214 - val_accuracy: 0.5000\n",
      "Epoch 896/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.5000\n",
      "Epoch 897/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.7693 - val_accuracy: 0.5000\n",
      "Epoch 898/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.7902 - val_accuracy: 0.5000\n",
      "Epoch 899/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.8095 - val_accuracy: 0.5000\n",
      "Epoch 900/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.8207 - val_accuracy: 0.5000\n",
      "Epoch 901/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.8229 - val_accuracy: 0.5000\n",
      "Epoch 902/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.8186 - val_accuracy: 0.5000\n",
      "Epoch 903/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.8097 - val_accuracy: 0.5000\n",
      "Epoch 904/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.5000\n",
      "Epoch 905/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.7622 - val_accuracy: 0.5000\n",
      "Epoch 906/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.7499 - val_accuracy: 0.5000\n",
      "Epoch 907/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.7474 - val_accuracy: 0.5000\n",
      "Epoch 908/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.7464 - val_accuracy: 0.5000\n",
      "Epoch 909/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.7441 - val_accuracy: 0.5000\n",
      "Epoch 910/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.7432 - val_accuracy: 0.5000\n",
      "Epoch 911/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.5000\n",
      "Epoch 912/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.7475 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.5000\n",
      "Epoch 914/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7040 - val_accuracy: 0.5000\n",
      "Epoch 915/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.6943 - val_accuracy: 0.5000\n",
      "Epoch 916/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.5000\n",
      "Epoch 917/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6998 - val_accuracy: 0.5000\n",
      "Epoch 918/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.7050 - val_accuracy: 0.5000\n",
      "Epoch 919/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.5000\n",
      "Epoch 920/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7277 - val_accuracy: 0.5000\n",
      "Epoch 921/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7455 - val_accuracy: 0.5000\n",
      "Epoch 922/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.5000\n",
      "Epoch 923/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.7720 - val_accuracy: 0.5000\n",
      "Epoch 924/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.5000\n",
      "Epoch 925/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.7840 - val_accuracy: 0.5000\n",
      "Epoch 926/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.5000\n",
      "Epoch 927/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.5000\n",
      "Epoch 928/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.7658 - val_accuracy: 0.5000\n",
      "Epoch 929/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7476 - val_accuracy: 0.5000\n",
      "Epoch 930/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.7244 - val_accuracy: 0.5000\n",
      "Epoch 931/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.7036 - val_accuracy: 0.5000\n",
      "Epoch 932/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6818 - val_accuracy: 0.5000\n",
      "Epoch 933/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.5000\n",
      "Epoch 934/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6548 - val_accuracy: 0.5000\n",
      "Epoch 935/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.5000\n",
      "Epoch 936/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6482 - val_accuracy: 0.5000\n",
      "Epoch 937/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.5000\n",
      "Epoch 938/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.5000\n",
      "Epoch 939/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6489 - val_accuracy: 0.5000\n",
      "Epoch 940/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.6487 - val_accuracy: 0.5000\n",
      "Epoch 941/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.5000\n",
      "Epoch 942/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.5000\n",
      "Epoch 943/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6487 - val_accuracy: 0.5000\n",
      "Epoch 944/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6517 - val_accuracy: 0.5000\n",
      "Epoch 945/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.5000\n",
      "Epoch 946/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6730 - val_accuracy: 0.5000\n",
      "Epoch 947/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.5000\n",
      "Epoch 948/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6944 - val_accuracy: 0.5000\n",
      "Epoch 949/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7103 - val_accuracy: 0.5000\n",
      "Epoch 950/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7320 - val_accuracy: 0.5000\n",
      "Epoch 951/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7561 - val_accuracy: 0.5000\n",
      "Epoch 952/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.7730 - val_accuracy: 0.5000\n",
      "Epoch 953/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7856 - val_accuracy: 0.5000\n",
      "Epoch 954/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7979 - val_accuracy: 0.5000\n",
      "Epoch 955/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.8015 - val_accuracy: 0.5000\n",
      "Epoch 956/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7888 - val_accuracy: 0.5000\n",
      "Epoch 957/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.7594 - val_accuracy: 0.5000\n",
      "Epoch 958/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7222 - val_accuracy: 0.5000\n",
      "Epoch 959/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6907 - val_accuracy: 0.5000\n",
      "Epoch 960/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6608 - val_accuracy: 0.5000\n",
      "Epoch 961/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.5000\n",
      "Epoch 962/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.6281 - val_accuracy: 0.5000\n",
      "Epoch 963/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6221 - val_accuracy: 0.5000\n",
      "Epoch 964/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.5000\n",
      "Epoch 965/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6001 - val_accuracy: 0.5000\n",
      "Epoch 966/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5925 - val_accuracy: 0.5000\n",
      "Epoch 967/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5962 - val_accuracy: 0.5000\n",
      "Epoch 968/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6064 - val_accuracy: 0.5000\n",
      "Epoch 969/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6201 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.5000\n",
      "Epoch 971/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6634 - val_accuracy: 0.5000\n",
      "Epoch 972/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6871 - val_accuracy: 0.5000\n",
      "Epoch 973/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7157 - val_accuracy: 0.5000\n",
      "Epoch 974/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7389 - val_accuracy: 0.5000\n",
      "Epoch 975/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7531 - val_accuracy: 0.5000\n",
      "Epoch 976/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.7662 - val_accuracy: 0.5000\n",
      "Epoch 977/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7768 - val_accuracy: 0.5000\n",
      "Epoch 978/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7852 - val_accuracy: 0.5000\n",
      "Epoch 979/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7908 - val_accuracy: 0.5000\n",
      "Epoch 980/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7945 - val_accuracy: 0.5000\n",
      "Epoch 981/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7933 - val_accuracy: 0.5000\n",
      "Epoch 982/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7896 - val_accuracy: 0.5000\n",
      "Epoch 983/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.5000\n",
      "Epoch 984/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.5000\n",
      "Epoch 985/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7585 - val_accuracy: 0.5000\n",
      "Epoch 986/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7444 - val_accuracy: 0.5000\n",
      "Epoch 987/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7300 - val_accuracy: 0.5000\n",
      "Epoch 988/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7152 - val_accuracy: 0.5000\n",
      "Epoch 989/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.7040 - val_accuracy: 0.5000\n",
      "Epoch 990/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7022 - val_accuracy: 0.5000\n",
      "Epoch 991/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7065 - val_accuracy: 0.5000\n",
      "Epoch 992/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7156 - val_accuracy: 0.5000\n",
      "Epoch 993/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.5000\n",
      "Epoch 994/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7269 - val_accuracy: 0.5000\n",
      "Epoch 995/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7231 - val_accuracy: 0.5000\n",
      "Epoch 996/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7245 - val_accuracy: 0.5000\n",
      "Epoch 997/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.7275 - val_accuracy: 0.5000\n",
      "Epoch 998/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7286 - val_accuracy: 0.5000\n",
      "Epoch 999/1000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7356 - val_accuracy: 0.5000\n",
      "Epoch 1000/1000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7393 - val_accuracy: 0.5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "mean_run_scores = []\n",
    "for i in trange(n_runs, desc='Runs'): \n",
    "    histories = []\n",
    "    \n",
    "    data = list((zip(real_data_splits_train_images, \\\n",
    "                                    real_data_splits_test_images, simulated_data_splits_train_images)))[0]\n",
    "    train_set, test_set, simulated_train_set = data[0], data[1], data[2]\n",
    "    \n",
    "    #for train_set, test_set, simulated_train_set in tqdm(zip(real_data_splits_train_images, \\\n",
    "    #                                real_data_splits_test_images, simulated_data_splits_train_images), total=20, desc='Folds'):\n",
    "        \n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "        \n",
    "        #print(X_test[0])\n",
    "        \n",
    "        #plt.imshow(X_test[1], origin='lower') \n",
    "        \n",
    "        # Adding simulated data. \n",
    "    X_train, y_train = add_simulated_data(X_train, y_train, simulated_train_set)   \n",
    "\n",
    "    print(X_train[0].shape)\n",
    "    print(y_train.shape) \n",
    "    \n",
    "\n",
    "    # Shuffling training data\n",
    "    temp_train = list(zip(X_train, y_train.tolist()))\n",
    "    random.shuffle(temp_train)\n",
    "    X_train, y_train = zip(*temp_train)\n",
    "\n",
    "    model = create_and_train(np.asarray(X_train), np.asarray(y_train), np.asarray(X_test), y_test)\n",
    "        \n",
    "    mean_run_score = mean_score_of_run(histories=histories, epochs=n_epochs)\n",
    "    mean_run_scores.append(mean_run_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 72, 36, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 70, 34, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 35, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19040)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2437248   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 2,463,928\n",
      "Trainable params: 2,463,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game = real_data_splits_train[0][0][0]\n",
    "image = create_image(game, components=[True, True, True, True, True])#[True, False, False, False, False]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20e3756c908>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAJWCAYAAAA3Pm4CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfI0lEQVR4nO3de7BlZXnn8e9j0zRyExsFW8E0KKKUo4AtUMExUYghRgWvkURtMiRUEnXAYSaSjKWY0ipNRjBjqjR4gdZ44WIQYhKV6YCUMwq03ARBQURAkEau0kpze+aPtY4cj+eyn9Nn7b32Od9P1a6911r78vSq7l+/a69nvysyE0nS4B436gIkadwYnJJUZHBKUpHBKUlFBqckFRmcklS01agLGMSy7bfLrVaunHbbips3DbkaSUvBA2ziwdwc020bi+DcauVKnnr8cdNue+Y7vjXkaiQtBRfl+hm3eaguSUUGpyQVGZySVGRwSlKRwSlJRWNxVn3FzZtmPHt+/ckHzfg6z7hL6oIjTkkqMjglqcjglKQig1OSigxOSSoyOCWpaCzakWYzW8vRbK1Kc71WkmbiiFOSigxOSSoyOCWpyOCUpCKDU5KKDE5JKhr7dqTZzNVu5MxKkubDEackFRmcklRkcEpSkcEpSUUGpyQVGZySVGRwSlLRou7jnMuWTEk3n/eUtDg44pSkIoNTkooMTkkqMjglqcjglKQig1OSijprR4qIvYHTJ63aE3g38Ol2/WrgRuANmXl3V3XM13zbipyqTlr8OhtxZub3MnPfzNwXeAHwc+Bs4ARgfWbuBaxvlyVpbAzrUP0Q4AeZ+SPgcGBdu34dcMSQapCkBTGs4Hwj8Pn28a6ZeRtAe7/LkGqQpAXReXBGxNbAq4Azi687JiI2RMSGh9jcTXGSNA/DGHH+HnBpZt7eLt8eEasA2vuN070oM0/JzDWZuWY5K4ZQpiQNZhjBeSSPHaYDnAusbR+vBc4ZQg2StGAiM7t784htgZuBPTPz3nbdzsAZwNOBm4DXZ+Zds73PjrEyD4xDOqtzWGxVksbHRbme+/KumG5bp9PKZebPgZ2nrLuT5iy7JI0lfzkkSUUGpyQVGZySVGRwSlKRwSlJRUv6Ym3D1sXF4eZ6X0kLzxGnJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkO1JPbElL0XxbmWxjkubHEackFRmcklRkcEpSkcEpSUUGpyQVGZySVGQ70iIw37Yi25ik+XHEKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVGQf5xI27P7PLflMqU8ccUpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRbYjqcwrcmqpc8QpSUUGpyQVGZySVGRwSlKRwSlJRQanJBXZjqSh8oqcWgwccUpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRbYjaSyM4sJyWto2f2jmv3OOOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkosjMUdcwpxVP3z2fevxxoy7jl5xxR1r8Lsr13Jd3xXTbHHFKUpHBKUlFBqckFRmcklRkcEpSkcEpSUWdzo4UETsBnwCeCyTwX4DvAacDq4EbgTdk5t2zvc+Kmzf1qgVoFDPu9OnPLy11XY84/x74SmY+G3g+cA1wArA+M/cC1rfLkjQ2OgvOiNgReDHwSYDMfDAz7wEOB9a1T1sHHNFVDZLUhS5HnHsCdwCnRsRlEfGJiNgO2DUzbwNo73fpsAZJWnBdBudWwP7ARzNzP2AThcPyiDgmIjZExIaH2NxVjZJU1mVw3gLckpkXtctn0QTp7RGxCqC93zjdizPzlMxck5lrlrOiwzIlqaaz4MzMnwA3R8Te7apDgO8C5wJr23VrgXO6qkGSutD1xdreDnw2IrYGbgD+mCasz4iIo4GbgNd3XIMkLaixmFZux1iZB8Yhoy5jpObbO2r/pzQ/TisnSQvI4JSkIoNTkooMTkkqMjglqcjglKSirvs4tUDm21bkFHjSwnPEKUlFBqckFRmcklRkcEpSkcEpSUUGpyQV2Y60yI2iNciZnLTYOeKUpCKDU5KKDE5JKjI4JanI4JSkIoNTkopsR9KCG/ZMTrYxadgccUpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRbYjqTdGcUE6W5k0H444JanI4JSkIoNTkooMTkkqMjglqcjglKQi25E09rakpWhLWpm0uG3+0Mx/rxxxSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFtiNpSXN2JM3kztw04zZHnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVNTpVS4j4kbgZ8AjwMOZuSYiVgKnA6uBG4E3ZObdXdYhSQtpGCPOl2Tmvpm5pl0+AVifmXsB69tlSRobozhUPxxY1z5eBxwxghokad66Ds4EvhYR346IY9p1u2bmbQDt/S4d1yBJC6rT7ziBgzPz1ojYBTgvIq4d9IVt0B4DsA3bdlWfJJV1OuLMzFvb+43A2cABwO0RsQqgvd84w2tPycw1mblmOSu6LFOSSjoLzojYLiJ2mHgMvAy4CjgXWNs+bS1wTlc1SFIXujxU3xU4OyImPudzmfmViLgEOCMijgZuAl7fYQ2StOA6C87MvAF4/jTr7wQO6epzJalr/nJIkooMTkkqMjglqcjglKQig1OSigxOSSoyOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkIoNTkooMTkkqMjglqcjglKQig1OSigxOSSoyOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkIoNTkooMTkkqMjglqWirURcgSaN0/ckHTbt+84e+NeNrHHFKUpHBKUlFBqckFRmcklRkcEpSkcEpSUWldqSIeCKwe2Ze2VE9krTgZmo5AnjmO6ZvO7ozN834mjlHnBFxQUTsGBErgSuAUyPipDkrlaRFapBD9Sdk5n3Aa4BTM/MFwKHdliVJ/TVIcG4VEauANwBf7rgeSeq9QYLzb4CvAj/IzEsiYk/gum7LkqT+mvPkUGaeCZw5afkG4LVdFiVJfTbIyaFnRcT6iLiqXX5eRLyr+9IkqZ8GaUf6OPA/gH8EyMwrI+JzwPu6LEySBjVbuxHM3HI0X4N8x7ltZl48Zd3DC1qFJI2RQYLzpxHxDCABIuJ1wG2dViVJPTbIofpbgVOAZ0fEj4EfAm/qtCpJ6rFBzqrfABwaEdsBj8vMn3VfliT114zBGRH/bYb1AGSmP7uUtCTNNuLcob3fG3ghcG67/Ergwi6LkqQ+mzE4M/O9ABHxNWD/iUP0iDiRSQ3xkjQM85nhqCuDnFV/OvDgpOUHgdWdVCNJY2CQs+qfAS6OiLPb5SOAdd2VJEn9NshZ9fdHxL8D/5mml/OPM/OyziuTpJ4adAb4R4BHaYLz0e7KkaT+G2SSj2OBzwJPAnYB/iki3t51YZLUV4OMOI8GDsxsLsARER8Evgl8pMvCJKmvBgnOoDlUn/BIu06SFlSfWo5mM0hwngpcNOWs+ie7K0mS+m2Qs+onRcQFwItoRpqeVZe0pM0ZnBFxEHB1Zl7aLu8QEQdm5kWdVydJPTTIL4c+Ctw/aXlTu06SlqRBgjMyMycWMvNRBu//lKRFZ5DgvCEi/mtELG9vxwI3dF2YJPXVIMH5Z8BvAj8GbgEOBI4Z9AMiYllEXBYRX26X94iIiyLiuog4PSK2nk/hkjQqg5xV3wi8cQs+41jgGmDHdvmDwMmZ+YWI+BhNg73fmUpLxLj0as5mkBHnvEXEbsDvA59olwN4KXBW+5R1NH2hkjQ2Og1O4MPAX/LYxCA7A/dk5sTlhW8BntZxDZK0oDoLzoh4BbAxM789efU0T81p1hERx0TEhojY8BCbO6lRkuajfLG2CQNcrO1g4FUR8XJgG5rvOD8M7BQRW7Wjzt2AW2d4/1NoLkvMjrFy2nCVpFGYbcS5Q3tbA/w5zSH102jOsu8z1xtn5l9l5m6ZuZrm5NJ/ZOYfAecDr2ufthY4Z97VS9IIjOJibe8EvhAR7wMuwwlDJI2ZQX4BtMUXa8vMC4AL2sc3AAdUXi9pvCyGlqPZVC/WlsCr8WJtkpaw6sXawGnlJC1xswZnRDwOuDIznwtcOpySJKnfZu3jbGdCuiIinj6keiSp9wb5jnMVcHVEXEwzFycAmfmqzqqSpB4bJDjf23kVkjRGBjk59PVhFCJpvCz2lqPZzPlb9Yg4KCIuiYj7I+LBiHgkIu4bRnGS1EeDTPLxD8CRwHXA44E/addJ0pI00LWDMvP6iFiWmY8Ap0bE/+u4LknqrUGC8+ft5S0uj4i/BW4Dtuu2LEnqr0EO1d/cPu9tNO1IuwOv7bIoSeqzQUacPwUezMwHgPdGxDJgRbdlSVJ/DRKc64FDgfvb5ccDX6O58qWkRWq2diNY/C1HsxnkUH2bzJwITdrH23ZXkiT12yDBuSki9p9YiIgXAL/oriRJ6rdBDtWPA86MiIlrA60C/qC7kiSp3wb5yeUlEfFsYG+aq1Rem5kPdV6ZJPXUoA3wDwFXdVyLJI2Fzq6rLkmL1UAjTkmL01Ke4WhLDDI70qsj4gmTlneKiCO6LUuS+muQQ/X3ZOa9EwuZeQ/wnu5KkqR+GyQ4p3uOh/iSlqxBgnNDRJwUEc+IiD0j4mTg210XJkl9NUhwvh14EDgdOBN4AHhrl0VJUp8N0gC/CThhCLVI0liYMTgj4sOZeVxE/AuQU7d7eWBpPNhytPBmG3F+pr3/X8MoRJLGxYzBmZnfbu+9PLAkTTJIA/wrIuKyiLgrIu6LiJ95eWBJS9kg/ZgfBl4DfCczf+27TklaagZpR7oZuMrQlKTGICPOvwT+LSK+DmyeWJmZJ3VWlST12CDB+X6aC7VtA2zdbTmS5sOWo+EaJDhXZubLOq9EksbEIN9x/p+IMDglqTVIcL4V+EpE/MJ2JEka7LfqOwyjEEkaFwPNqxkRTwT2ojlBBEBmXthVUZLUZ3MGZ0T8CXAssBtwOXAQ8E3gpd2WJkn9NMh3nMcCLwR+lJkvAfYD7ui0KknqsUEO1R/IzAcigohYkZnXRsTenVcm6VfYq9kfgwTnLRGxE/Al4LyIuBu4tduyJKm/Bjmr/ur24YkRcT7wBOArnVYlST026Fn1ZcCuwA/bVU8BbuqqKEnqs0HOqr+d5jrqtwOPtqsTeF6HdUlSbw0y4jwW2Dsz7+y6GEkaB4POx3lv14VI0rgYZMR5A3BBRPwrzscpdcqWo/EwSHDe1N62xvk4JWmg4PxiZl7VeSWSNCYG+Y7zYxFxcUT8RdsIL0lL2pzBmZkvAt4E7A5siIjPObGxpKVskBEnmfl94F3AO4HfAv4+Iq6NiNd0WZwk9dGcwRkRz4uIk4FraKaSe2VmPqd9fHLH9UlS7wxycugfgI8Df52Zv5hYmZm3RsS7OqtMWoRmazcCW47GxSCTfLw4Ip4MbA/8Ysq2z3RVmCT11YyH6tE4MSLuAK4Fvh8Rd0TEu4dXniT1z2zfcR4HHAwckJk7Z+YTgQOBgyPiHUOpTpJ6aLbgfAtwZGZOTCVHZt5A05r0lq4Lk6S+mi04l2fmT6euzMw7gOXdlSRJ/TZbcD44z22StKjNdlb9+RFx3zTrg0nXV59JRGwDXAisaD/nrMx8T0TsAXwBWAlcCrw5Mw1iLRrOcLT4zTjizMxlmbnjNLcdMnOQQ/XNwEsz8/nAvsBhEXEQ8EHg5MzcC7gbOHoh/iCSNCwD/eRyPrJxf7u4vL0lzS+OzmrXrwOO6KoGSepCZ8EJzUXeIuJyYCNwHvAD4J7MfLh9yi3A07qsQZIWWqfBmZmPZOa+wG7AAcBzpnvadK+NiGMiYkNEbHjosYnnJWnkOg3OCZl5D3ABcBCwU0RMnJTaDbh1hteckplrMnPNclYMo0xJGkhnwRkRT56Y+DgiHg8cSjPD0vnA69qnrQXO6aoGSerCILMjzdcqYF1ELKMJ6DMy88sR8V3gCxHxPuAy4JMd1iB1wpajpa2z4MzMK4H9pll/A833nZI0lobyHackLSYGpyQVGZySVGRwSlKRwSlJRV22I0ljzZYjzcQRpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUtFY9HFu3n07rj9+5p46qQv2amomjjglqcjglKQig1OSigxOSSoyOCWpyOCUpKKxaEdacfMmW0Mk9YYjTkkqMjglqcjglKQig1OSigxOSSoyOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkIoNTkooMTkkqMjglqcjglKQig1OSigxOSSoyOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkIoNTkooMTkkqMjglqcjglKQig1OSigxOSSoyOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkIoNTkooMTkkqMjglqcjglKQig1OSigxOSSrqLDgjYveIOD8iromIqyPi2Hb9yog4LyKua++f2FUNktSFLkecDwPHZ+ZzgIOAt0bEPsAJwPrM3AtY3y5L0tjoLDgz87bMvLR9/DPgGuBpwOHAuvZp64AjuqpBkrowlO84I2I1sB9wEbBrZt4GTbgCuwyjBklaKJ0HZ0RsD3wROC4z7yu87piI2BARGx5ic3cFSlJRp8EZEctpQvOzmfnP7erbI2JVu30VsHG612bmKZm5JjPXLGdFl2VKUkmXZ9UD+CRwTWaeNGnTucDa9vFa4JyuapCkLmzV4XsfDLwZ+E5EXN6u+2vgA8AZEXE0cBPw+g5rkKQF11lwZuY3gJhh8yFdfa4kdc1fDklSkcEpSUUGpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVGZySVGRwSlKRwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFRmcklRkcEpSkcEpSUUGpyQVbdXVG0fEp4BXABsz87ntupXA6cBq4EbgDZl5d1c1aGm4/uSDRl2CFqHNH/rWjNu6HHGeBhw2Zd0JwPrM3AtY3y5L0ljpLDgz80LgrimrDwfWtY/XAUd09fmS1JVhf8e5a2beBtDe7zLkz5ekLdbZd5xbKiKOAY4B2IZtR1yNJD1m2CPO2yNiFUB7v3GmJ2bmKZm5JjPXLGfF0AqUpLkMOzjPBda2j9cC5wz58yVpi3XZjvR54LeBJ0XELcB7gA8AZ0TE0cBNwOu7+vwu2f7SL898x8xtI9J83ZmbZtzWWXBm5pEzbDqkq8+UpGHwl0OSVGRwSlKRwSlJRQanJBUZnJJUZHBKUlFvf3I52ebdt+P64/vTO2nfoLS0OeKUpCKDU5KKDE5JKjI4JanI4JSkIoNTkorGoh1pxc2bbAGS1BuOOCWpyOCUpCKDU5KKDE5JKjI4JanI4JSkorFoR1I3ZrtaZ1ftX1+99fIZtz3j9D+bcZvtaOoTR5ySVGRwSlKRwSlJRQanJBUZnJJUZHBKUlFk5qhrmNOOsTIPjENGXcYWG0X7z3z1rVbbmDRsF+V67su7YrptjjglqcjglKQig1OSigxOSSoyOCWpyOCUpCLbkRbYfNt4Zmu3AVtupGGzHUmSFpDBKUlFBqckFRmcklRkcEpSkcEpSUVLuh2pbzMAaeHZ5qX5sh1JkhaQwSlJRQanJBUZnJJUZHBKUpHBKUlFBqckFW016gK6NFufJiyePj2vADmz333qvrNufyaLfx9o4TnilKQig1OSigxOSSoyOCWpyOCUpCKDU5KKxr4dqaup4capxWe2lhvbbaSF54hTkooMTkkqMjglqcjglKQig1OSikYSnBFxWER8LyKuj4gTRlGDJM3X0K9yGRHLgO8DvwPcAlwCHJmZ353pNSuevns+9fjjpt22FGb46RuvHKmloG9XuTwAuD4zb8jMB4EvAIePoA5JmpdRBOfTgJsnLd/SrpOksTCK4Jxu6Ptr3xdExDERsSEiNjxy/6YhlCVJgxlFcN4C7D5peTfg1qlPysxTMnNNZq5Ztv12QytOkuYyiuC8BNgrIvaIiK2BNwLnjqAOSZqXoU/ykZkPR8TbgK8Cy4BPZebVw65DkuZr6O1I8xERdwA/ahefBPx0hOVMZT2z61M9faoFrGcuo67nNzLzydNtGIvgnCwiNmTmmlHXMcF6ZtenevpUC1jPXPpWz2T+5FKSigxOSSoax+A8ZdQFTGE9s+tTPX2qBaxnLn2r55fG7jtOSRq1cRxxStJIjVVw9m06uoi4MSK+ExGXR8SGEXz+pyJiY0RcNWndyog4LyKua++fOMJaToyIH7f75/KIePkwamk/e/eIOD8iromIqyPi2Hb9qPbPTPUMfR9FxDYRcXFEXNHW8t52/R4RcVG7b05vf6DSuVnqOS0ifjhp38x8VcJhy8yxuNE0y/8A2BPYGrgC2GfENd0IPGmEn/9iYH/gqknr/hY4oX18AvDBEdZyIvDfR7RvVgH7t493oJnKcJ8R7p+Z6hn6PqKZL2L79vFy4CLgIOAM4I3t+o8Bfz7iek4DXjeKvz9z3cZpxOl0dFNk5oXAXVNWHw6sax+vA44YYS0jk5m3Zeal7eOfAdfQzMI1qv0zUz1Dl43728Xl7S2BlwJnteuHuW9mqqe3xik4+zgdXQJfi4hvR8QxI65lwq6ZeRs0/1iBXUZcz9si4sr2UH4oh8VTRcRqYD+akczI98+UemAE+ygilkXE5cBG4Dyao7l7MvPh9ilD/fc1tZ7MnNg372/3zckRsWJY9cxlnIJzoOnohuzgzNwf+D3grRHx4hHX0zcfBZ4B7AvcBnxo2AVExPbAF4HjMvO+YX/+APWMZB9l5iOZuS/N7GQHAM+Z7mnDqGW6eiLiucBfAc8GXgisBN45rHrmMk7BOdB0dMOUmbe29xuBs2n+Ao7a7RGxCqC93ziqQjLz9vYfxKPAxxny/omI5TQh9dnM/Od29cj2z3T1jHofZeY9wAU03ynuFBETE/+M5N/XpHoOa7/eyMzcDJxKP/59AeMVnL2aji4itouIHSYeAy8Drpr9VUNxLrC2fbwWOGdUhUwEVOvVDHH/REQAnwSuycyTJm0ayf6ZqZ5R7KOIeHJE7NQ+fjxwKM13rucDr2ufNsx9M1091076Dy5ovm/tw7+vxqjPTlVuwMtpzkb+APifI65lT5oz+1cAV4+iHuDzNId3D9GMyI8GdgbWA9e19ytHWMtngO8AV9IE1qoh7psX0RxqXglc3t5ePsL9M1M9Q99HwPOAy9rPvAp4d7t+T+Bi4HrgTGDFkPbNTPX8R7tvrgL+ifbMex9u/nJIkorG6VBdknrB4JSkIoNTkooMTkkqMjglqcjglKQig1O90f5e+U8j4usRcVdEPNROVXdlRHwiIl416blHRURGxFEjLFlL1NCvqy5NJyKWAV8GDgPuAf6VppF+Jc1vuf+Q5nfLI/u1mDTB4FRfHEkTmlcAv5WZ907eGBHbAgeOojBpKg/V1Re/2d6fNjU0ATLz55l5PkBEXEAz6QPAqe0h+8Rt9cRrImKriPiLiPhWRNwXET+PiMsi4m0R8St/9yNidfv60yLi2RHxpfbrgk0R8Y2IeFkXf2iNJ0ec6os72/tnDfDc02gO5w+nmYji8knb7oFfzkT0L8DvAt8DPgc8ALwE+AjN6PXN07z3HsA3aX4f/Y80M7f/AfDvEfGHmXl65Q+lRWrUP5b35i0zoZnY90HgUZqJL14D/MYszz+KZtKMo2bYfmK7/SPAsknrl9HMUpTA4ZPWr27XJfB3U95rDc3kJXcDO456X3kb/c1DdfVCZl4GvAm4vb3/InBjRNwZEWdHxCsHfa/2MPxtwE+Ad2TmI5M+5xHgeJqA/KNpXn4v8DdTatsAfBbYiWbqNy1xHqqrNzLzjIg4m+Zw+kU0o9AX0czFeEREfJpmhDnXlF7Popk+7jrgXc10jr/mF0w/6/ml2VwTaKoLaOao3I/HrlmkJcrgVK9k5kPA19rbRJvSa4FPAW+hmWn/S3O8zc7t/V7Ae2Z53vbTrLt9huf+pL1/whyfrSXAQ3X1WjaXlTgDOLld9dIBXjZxVv7szIxZbntM89pdZ3jPp0x5by1hBqfGxcTh88Rx98T3lsumee61NGfXD2rPrlfsP3FJlCl+u72/rPh+WoQMTvVCRBwZEb8ztb+y3fYU4E/bxQvb+4n2padPfX42l7j9CE0r0f9ur2Mz9T1XRcQ+05TyBODdU567huZE0r00XxVoifPSGeqFiPgwcCzNd4nfAH7YbtoD+H3g8TQ9m6/OzGyvP34L8DDwaR77bvIjmXlvO9I8C3gV8GOa69f8mOY66nsBB9NcJ+oD7eevbj/zQppr4HwH+L881se5NWAfpwCDUz0REbvThNyhwD40gbUNzcjyMpoG9s9lcxndidccRnPy5z8B27Wr98jMG9vtQdPadBTN2fDtgTtoAvLfgM9k5s3tc1e369cBHwQ+ALwYWNF+/t9k5lc7+KNrDBmcEr8anJl51EiLUe/5HackFRmcklRkcEpSkd9xSlKRI05JKjI4JanI4JSkIoNTkooMTkkqMjglqej/A5x6L20dUv2fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Step', fontsize=20)\n",
    "plt.ylabel('Dynamic card codes')\n",
    "plt.imshow(image, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "img = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "img_tensor = np.expand_dims(img, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "activations = activation_model.predict(img_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x592.941 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x592.941 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x592.941 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for l in range(4,5):\n",
    "    for i in range(4):\n",
    "        layer_activation = activations[i]\n",
    "        plt.matshow(layer_activation[0, :, :, l], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_layer_activation = activations[4]\n",
    "#plt.matshow(first_layer_activation[0], cmap='viridis')##\n",
    "first_layer_activation = np.expand_dims(first_layer_activation, axis=0)\n",
    "first_layer_activation = first_layer_activation[:, :, :40]\n",
    "first_layer_activation.shape\n",
    "plt.matshow(first_layer_activation[0, :, :], cmap='viridis')\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_layer_activation = activations[5]\n",
    "#plt.matshow(first_layer_activation[0], cmap='viridis')##\n",
    "first_layer_activation = np.expand_dims(first_layer_activation, axis=0)\n",
    "first_layer_activation = first_layer_activation[:, :, :40]\n",
    "first_layer_activation.shape\n",
    "plt.matshow(first_layer_activation[0, :, :], cmap='viridis')\n",
    "plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_layer_activation = activations[6]\n",
    "#plt.matshow(first_layer_activation[0], cmap='viridis')##\n",
    "first_layer_activation = np.expand_dims(first_layer_activation, axis=0)\n",
    "first_layer_activation = first_layer_activation[:, :, :40]\n",
    "first_layer_activation.shape\n",
    "plt.matshow(first_layer_activation[0, :, :], cmap='viridis')\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_layer_activation = activations[7]\n",
    "#plt.matshow(first_layer_activation[0], cmap='viridis')##\n",
    "first_layer_activation = np.expand_dims(first_layer_activation, axis=0)\n",
    "first_layer_activation = first_layer_activation[:, :, :40]\n",
    "first_layer_activation.shape\n",
    "plt.matshow(first_layer_activation[0, :, :], cmap='viridis')\n",
    "plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
