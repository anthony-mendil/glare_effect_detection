

\begin{abstractgerman}
Die Leistungsfähigkeit von Menschen in der Interaktion mit Computern kann durch verschiedene Hindernisse beeinträchtigt werden. Man bezeichnet sie als Hindernisse der Mensch-Computer-Interaktion. Es ist möglich kognitive adaptive Systeme zu implementieren, die diese Hindernisse durch geeignete Anpassungen der Benutzerschnittstelle kompensieren. Damit eine solche Kompensation möglich ist, müssen solche Hindernisse jedoch zuerst erkannt werden. In dieser Arbeit wird ein flüchtiges visuelles Interaktionshindernis namens Blendeffekt auf der Grundlage von Verhaltensdaten von 20 Testpersonen erkannt, die ein Memory Spiel spielen, bei dem das Ziel ist Karten mit gleichen Farben zu finden. Der Blendeffekt beschreibt ein Szenario, in dem Sonnenlicht auf den Bildschirm scheint und somit zu einer geringeren Unterscheidbarkeit der Farben führt. Zur Erkennung dieses Hindernisses werden ein- und zweidimensionale convolutional neural networks (1D convnets und 2D convnets) verwendet. Während 1D convnets ein üblicher Ansatz für Sequenz-Klassifikationen sind, werden 2D convnets eher im Bereich der Bildverarbeitung eingesetzt. In dieser Arbeit wird jedoch ein neuartiger Ansatz implementiert, der darin besteht, aus den sequentiellen Daten synthetische Bilder zu erzeugen und 2D convnets zur Klassifikation dieser Bilder zu verwenden. Entsprechend wird ein ursprüngliches Sequenz-Klassifikationsproblem in den Bereich der Bildverarbeitung überführt. Um die Menge verfügbarer Trainingsdaten zu erhöhen, wird ein kognitiver Benutzersimulator verwendet, der unter Verwendung eines generativen Optimierungsalgorithmus neue Verhaltensdaten simuliert. Die Performanz der 1D und 2D convnets wird im Hinblick auf die Menge der simulierten Daten und die Anzahl der im Training enthaltenen Spielzüge analysiert. Darüber hinaus werden Änderungen am Simulator vorgenommen und die Performanz der Modelle vor und nach diesen Änderungen wird verglichen. Die Ergebnisse zeigen, dass 1D convnets bei der Erkennung des Hindernisses nach 5 und 10 Spielzügen bessere Ergebnisse erzielen als 2D convnets, während das Gegenteil nach 15 und 20 Zügen der Fall ist. Es werden vier ensemble-basierte Systeme implementiert, jeweils eines für 5, 10, 15 und 20 Züge. Die ersten beiden basieren auf 1D und die beiden anderen auf 2D convnets. Jedes dieser Systeme besteht aus mehreren Modellen, die abstimmen um die endgültige Entscheidung zu treffen. Die Genauigkeit dieser Systeme in der Reihenfolge der Anzahl der Züge beträgt 72,5\%, 82.5\%, 80\% und 85\%.  

\clearpage
\end{abstractgerman}
\newpage

\begin{abstract}
\label{sec:abstract}
The performance of humans interacting with computers can be impaired by several obstacles. Such obstacles are called Human Computer Interaction (HCI) obstacles. Cognitive adaptive systems can be implemented that compensate those obstacles with suitable User Interface (UI) adaptations. However, such obstacles first need to be detected. In this work, a transient visual HCI interaction obstacle called glare effect is detected based on behavioural data of 20 subjects playing a matching pairs game where the cards have different colours. The glare effect describes a scenario in which sunlight shines onto the display, resulting in less distinguishability of the colours. For the detection of this obstacle one and two dimensional convolutional neural networks (1D convnets and 2D convnets) are utilized. While 1D convnets are a common approach for sequence classifications, 2D convnets are generally more used in the area of computer vision. However, in this work a novel approach is implemented that consists of creating synthetic images out of the sequential data and using 2D convnets to classify the images, thus turning what was originally a sequence classification task into an image classification task. In order to increase the available training data a cognitive user simulator is used that implements a generative optimization algorithm to simulate behavioural data. The performance of the 1D and 2D convnets is analysed in regard to the the amount of simulated data and the number of game rounds included in the training. Furthermore, changes to the simulator are made and the performance of the models before and after the changes are compared. Results show that 1D outperform 2D convnets in detecting the obstacle after 5 and 10 rounds of the game, while 2D outperform 1D convnets in detecting it after 15 and 20 rounds. Four ensemble-based systems are implemented, one each for 5, 10, 15 and 20 rounds. The first two are based on 1D and the other two on 2D convnets. Each system consists of multiple models that vote for the final prediction. The accuracies of these systems in the order of the number of rounds are 72.5\%, 82.5\%, 80\% and 85\%.  


\clearpage
\end{abstract}

\begin{comment}
	\newpage
	
	- Einleitung: Was es für verschiedene Obstacles gibt, was schon gemacht wurde, was ich mache, wieso keine eeg daten obwohl sie da sind (sind interaktion obstacle zu erkennen und nutzung zu verbessern ist nicht da wenn man eeg maske tragen muss)\\\\
	- memory game kurz erklären\\\\
	- libraries und so die ich benutz habe? pandas keras..\\\\
	
	- \todo{vizualizing of intermediate activations reinnehmen? (ist auskommentiert!)}
	
	- \textbf{simulation}:\\
	- simulatin damit man mehr daten hat\\
	- generell simulator erklären und sinn von similarity matrix\\
	- similaity matrix erstelung und gedanken (plus anpassungen an memory game, anpassungen am simulator damit similarity matrix benutzt werden kann)\\
	- es gab invalid logs und hab code geschrieben der das überprüft damit man die rausnehmen kann. vor simulation (validLogsCollecot)\\
	- similarity matrix mapper, waren vorher nicht gmapped und mapper macht das und ersetz alte matrix durch die neue für glare effect\\
	- erklären wie ich korrektheit der matrix überprüft habe\\
	- erklären wie ich korrektheit der farbextraktion und unterschied berechnung überprüft habe (online rechner und anfangs matrix für no obst erstellt und mit alten verglichen aber gibg nicht weil struktur nicht zu erkennen war bei alter matrx von vorherigen arbeieten)\\
	- initially simulationergebnisse mit plots für qualität (plus erklärung)\\
	- sagen was noch nicht optimal und, was am simulator dafür geändert wurde (2 sachen: random decay ab 10 zügen plus eine andere sache) mit begründung und wie die ergebnisse am ende aussahen (zwischenschritte eher niht glaube ich. nur kurz erwähnen)\\
	- darüber reden wie es im realfall ist: wir benutzen nicht alle simualtionen sondern nur die besten, plots zeigen mi nur den besten (vor und nach änderung vielleicht, oder nur nach änderung (aber dann sieht man nicht das änderung sinnvoll war))\\
	- paried t-test kram um signifikante unterschiede /keine unterschiede zu zeigen für verschiedene bedingenen (siehe mazens nachricht)\\\\
	
	- \textbf{modelle}:\\
	- feature engenierring: also was die komponenten sind und so, wie sie berechnet wurden\\
	- für 1d cnn wuren die so übernommen\\
	- erklärung komponenten von 1d cnn \\
	- (villeicht auch mal nicht mit allen featires probieren, aber da hatte ich problme mit dem cnn. man müsste glaube ich die struktur ändern)\\
	- struktur 1 d cnn mit begründung\\ 
	- 2d cnn komponenten erklärunen (snythetic image erklären und zeigen wie berechnet wurde und wie es aussieht)\\
	- idee von 2d cnn für diesen fall\\
	- 2d cnn struktur erklären und begründen\\\\
	
	- \textbf{Training und analyse}:\\
	- vielleiht gucken welche falsch erkannt werden und woran es liegt, also wenn die zum beispiel echt schlect oder gut sind obwohl es nicht so sein sollte (rausnhemen und gucken wie ergebnisse sind, vielleicht nur bei bestem modell)\\
	- in gleichen tabellen ergebnise vor änderung am simulator und nach änderung betrachten und vergleichen\\
	- training auf welchem rechner/n,was von: cpu oder gpu oder beides, hardware kurz erwähnen, vpn (fernzugriff)\\
	- train test splt, leave one out k fold (+ begründung mit deep learing ..reliable results etc, randomness) \\
	- kurz erklären wieso weniger züge besser sind bei dieser hci erkennung\\
	- (vielleicht kram zu adaptive learning rate ändern und gucken wie es so ist, ansonsten begründen wieso ich das nicht brauche) \\
	- 20 steps und 40 steps für beide trainieren mit sd0x bis sd10x plus sd20x\\
	- (entweder so dass 1d cnn mit 20 steps auch konvergence erreicht oder danach nochmal anpassung von 20 steps 1d cnn damit es kovergiert)\\
	- darüber schreiben dass letzen n züge nicht mehr so gut simuliert sind (zeigen) und deshalb 40 steps nicht so viel besser ist \\
	- mit maximalen guten steps (glaube 16 züge oder so) trainieren und vergleichen\\
	- statistical tests um signifikante unterschiede /keine unterschiede zu zeigen für verschiedene modelle etc (siehe mazens nachricht)\\
	
	- in anhang alle skripte aufzählen wie markus 
	
	- \todo{tabbelen unterschrift muss glaube ich dadrunter und nicht drüber!}
	
	- special thanks to mazen for the great support. And special thanks to the csl for letting me use their servers for data storing and training.
	
	\section{Anmerkungen}
	Zitationen~\cite{Rabiner89-ATO} sind keine Wörter sondern Referenzen und stellen somit keinen Teil des Satzes dar. In anderen Worten: Der Satz muss auch noch funktionieren, wenn die Zitation einfach entfernt wird.
	
	
	%Index-Einträge~\index{example intro}
	
	Wir haben Tabellen~\ref{tab:example} und Bilder~\ref{fig:example}.
	
	\begin{table}
	\centering
	\begin{tabular}{llll}
	\toprule
	dies & ist & eine & Tabelle \\
	mit  &     & zwei & Zeilen \\
	\bottomrule
	\end{tabular}
	\caption[Tabelle mit kurzer Unterschrift]{Tabelle mit einer langen Unterschrift}
	\label{tab:example}
	\end{table}
	
	
	
	\begin{figure}
	\includegraphics[width=5cm]{logos/titlepage.eps}
	\caption[Bild kurz]{Bildunterschrift}
	\label{fig:example}
	\end{figure}
	
\end{comment}

