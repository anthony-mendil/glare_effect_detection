\chapter{Collected Data}
While the probands playes the memory game, behavioral data and brain activity data was collected. Relevant for this work is only the data recorded in glare effect and no obstacle games. The data was collected from 22 probands. \todo{grobe demographic herausfinden, mazen fragen}. 

\section{Behavioural data}
In order to record bavioural data, each card was initally given a fixed card code and is was recorded which pairs of cards were turned face up in each round. The card code consists of two numbers separated by a dot. The first number specifies the colour of the card (between 1 and 7 as there are 7 colours) and second number specifies if it is the first or second card with that color in the order of the cards on the field \todo{nachfragen ob das so ist, aber müsste weil am anfang zum beispiel 5.2}. The bevioral data was saved in logs, consisting of the card codes of each round followed by the unix timestamps of when the cards were flipped. Data of 20 rounds and therefore at maximum 40 flipped cards was recorded. If the game was completed in less than 20 turns, the remaining card code entries were filled with 0.0 and the remaining timestamp entries were filled with 0. An example of the sequence of card codes recorded during a game can be seen below.
\begin{verbatim*}
5.2,2.2,4.2,4.1,6.1,7.2,6.2,6.1,1.2,1.1,7.1,2.2,2.1,7.1,5.2,5.1,3.1,
2.1,7.1,3.1,7.2,7.1,3.2,2.2,2.1,2.2,3.1,3.2,0.0,0.0,0.0,0.0,0.0,0.0,
0.0,0.0,0.0,0.0,0.0,0.0
\end{verbatim*}

\todo{inital mapping herausfinden} With the assignments of for instance of 5 for red and 2 for green, the first two entries in the log file mean that first the second red card and then the first green card was turned face up. This mapping is static as colours have the same numbers across all recorded games. However, the simulator requires dynamic mapping of the card codes. Additionally dynamically mapped similarity values for the card codes are needed which are missing in the original logs.

By dynamic mapping of the card codes is meant, that the colours are not assigned to fixed numbers but that the numbers are assigned in the reveal order specific to each game. This becomes clear, by looking the card code sequence from above, but dynamically mapped.
\begin{verbatim*}
1.1,2.1,3.1,3.2,4.1,5.1,4.2,4.1,6.1,6.2,5.2,2.1,2.2,5.2,1.1,1.2,7.1,
2.2,5.2,7.1,5.1,5.2,7.2,2.1,2.2,2.1,7.1,7.2,0.0,0.0,0.0,0.0,0.0,0.0,
0.0,0.0,0.0,0.0,0.0,0.0
\end{verbatim*}

\todo{sobald ich originales mapping weiß, weiß ich auch welche farben die karten hatten und kann die folgenden farben im text ersetzen} In this dynamic mapping of the card codes, each entry likewise consists of 2 numbers that are seperated by a dot. However, the numbers are differently interpreted. The first number specifies what number of colour it is to be revealed and the second number specifies if it was the first or the second card in that colour. In the example above the colour green is the first to be revealed and it was the first green crad. Therefore the first entry is 1.1. Then a red card is turned face up, meaning the second entry is 2.1 since is was the first red card and so on. Once the other red card is dicovered, the entry will be 2.2. This pattern continues throughout the whole sequence. This means that the mapping is specific to each game and depends on the reveal order of the cards. The differnece bewteen static and dynamic similarity assignments is explained in section \todo{ref zu similarity matrix bei simulator und da erklären was die unterschiede sind und was der simulator benutzt? genauso köönte man dann aber auch die card codes mapping da erklären?}

Logs with remapped card codes and added similarity values were already provided, but there were two issues regarding the glare effect logs. The first one being that the similarity matrix for the glare effect game was just a placehoulder and did not correclty portray the color differneces under the influence of sunlight. To successfully simulate glare effect games the simulator requires such an similarity matrix. Therefore a new one is created in section ref. The second issue was that although the card codes were dynamically mapped, the similarity values were not. This meant that the assignment of simialrity values to numbers for the cards compared were identical in all games, but the numbers of the cards stood for different colours in different games. To solve this issue the newly created similarity matrix for the glare effect was used to determine the dynamically mapped similarity values for each game. The old values in the glare effect logs are then replaced with the new values and correct mapping in section ref. The reason why these issues only apply to glare effect logs and not to no obstacle logs is that the simulator does not use any similarity values when simulating no obstacle games, meaning that these values are ignored anyway. Therefore there is no need to replace them. It should also be noted that both the glare effect and the no obstacle logs additionally include four statistical features for the last turn. These consist of the number of remaining cards, the number of never revealed cards, the highest number of times the same card was revealed and the number of rounds since all pairs were found. These four values are also ignored, as they are newly calculated for every turn in section ref. Last but not least all logs end with a label, describing in which game mode the log was created. 

There are 22 no obstacle logs and 21 glare effect logs. One of the glare effect logs is invalid for simulating user behaviour. What makes them invalid and how they are filtered is explained in section \todo{ref}.

\section{Brain activity}

Eeg data collected from all proabnds during the game. However, there is one problem with using the eeg data: The overlyiong context of this work is to find interaction obstacles and ultimatley imporve the user interaction. This means that the way of discovering such an interaction obstacle should not worsen the interaction experience. If all people had to waer eeg masks when interacting with software just for the purpose of noticing interaction obstacles, the interaction experience itself would suffer. Additionally it is not cost efficient for every user to use and eeg sensor. As a result the decision was made not to use eeg data and instead only use the behvioural data that is collected direclty through the interaction and stays unnoticed by the user. As eeg data is not used in this work it will not be further explained. 




