\chapter{Conclusion}
\label{conclusion}
A similarity matrix was created that successfully describes the colour differences of the cards under the influence of the glare effect. It was used in a cognitive user simulator to accurately simulate glare effect games. This simulator was also used to simulate no obstacle games. It was attempted to improve the simulator, but it could not be clearly said if that was successful. Although there are some indications that the quality of the simulations was improved, there are also others findings that suggest the opposite. One of them being that the classification results using the simulations were worse after the changes to the simulator. Additional findings suggest that the  simulator performs less good in later rounds of the game. Furthermore, it was shown that incorporating certain amounts of simulated data improves the classification results significantly. 

For the classification of the visual interaction obstacle being the glare effect two approaches were implemented. Firstly, a 1D convnet was utilized that classifies a sequence of statistical features. The second approach was less common: Creating synthetic images out of the naturally sequential data and use 2D convnets to classify the created images. Classifiers for four different numbers of rounds were tested. While the best result for 5 and 10 rounds are achieved by the 1D convnets, the 2D convnets outperform the 1D convnets when using 15 and 20 rounds. Findings indicate a possibility that 2D convnets are less effected by inaccurate simulations than 1D convnets. 

Four ensemble-based systems, one each for 5, 10, 15 and 20 rounds were implemented, that decide the final classification by a voting of multiple models. The systems for 5 and 10 rounds utilize 1D convnets while those for 15 and 20 rounds 2D convnets. The accuracies of the four systems in the order of the number of rounds were 72.5\%, 82.5\%, 80.0\% and 85.0\%. As the topologies and the hyper parameters of the models are not individually optimized due to small number of recordings and instead best practice values were chosen it is advisable to collect data from new subjects and optimize the models before using them. Nevertheless, two different usages are suggested for such ensemble-based systems. If the requirement is to use a single system, the one trained to classify games after 10 rounds should be chosen, as the accuracy of 82.5\% is high and the decision is made relatively early in the game. Otherwise an option would be to use all four ensemble-based systems over the course of the game, depending on the number of rounds. This would mean making a prediction every 5 rounds until round 20 and adjusting the eventual adaptation accordingly. When considering that the glare effect is a transient visual obstacle, meaning that adaptation may not be necessary throughout the whole game, the second approach seems more sensible. Making a prediction each 5 rounds would bring the advantage of being able to switch the adaption on and off more often. Continuing the adaptation even though it is not needed any more can be harmful to the user experience and acceptance \cite[p.~1]{blind}. Contrary to that, in the case of persistent visual obstacles, such as colour blindness, multiple tests in different stages of the game are not useful, as the adaptation, if needed once, is needed throughout the whole game.

\section{Prospect}
\label{prospect}
Regarding the simulation of user behaviour, instead of only simulating once and using a number of the best simulations, it could be simulated multiple times to take only the single best simulation from each run. This could improve the overall quality of the simulations used to train the models. Regarding the simulator, further research could be done to find out whether it actually performs worse in later turns, as indicated by findings of this work. If this is the case and the reasons are discovered, further attempts could be made to improve the simulator.

Creating synthetic images out of sequential data and using the image for an image classification is very experimental and only one way of creating such images was tested in this work. Therefore, it could be analysed how different visual representations of the sequential data influence the performance of the classifier, as it is possible that a better representation exists. 
%- es wurde zwar impolementiert nicht alle features zu verwenden, aber es wurde nie ausprobiert. Hätte man testweise machn können. naja\\
%-Vielleicht hätte man ein weiteres statistical feature für penalties machen können, so wie es beim qualitätscheck der simulationnen berechnet wird. naja\\

As mentioned in section \ref{models} \nameref{models}, the data was only split into training and test data without separate validation data as the amount of game logs collected is very small. This is also the main reason why the models were not optimized, as a separate validation set would be needed. The models could be optimized on the validation data and then tested on the test data, assuring that they perform well on data that they have never seen before. A new user study could be performed in order to collect the necessary data to optimize the models. Such an optimization could significantly improve the classification results. 
%- a user study could be done to validate the voting based systems in real scenarios. As mentioned in chapter \todo{ref} the results shown in tabel \todo{ref zu table mit voting ergebnissen} 
%- real world sacenario 20 modelle ohne splits, offline test leace one out, online test
%- If addirional data wa collected in this study it could be used as validation set to optimize hyper parameters and topologies of models individually. 

Last but not least, it could be interesting to further investigate the creation of synthetic image and the rather unconventional usage of image recognition using 2D convnets on what was originally a sequence. In this work this approach outperformed the more conventional use of 1D convnets in multiple cases. There is a possibility that the 2D convnets were more capable in handling inaccurate simulations. Further research could potentially reveal that this is actually the case or that there are other aspects to using synthetic images and 2D convnets that make them outperform 1D convnets in certain sequence classifications. Both would be interesting findings. The first step could be to analyse whether this behaviour can still be observed after collecting additional data and optimizing the individual models.


