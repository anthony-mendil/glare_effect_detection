\chapter{Voting based system}

- Notiz für sastem: split1 hat ersten log nicht also index 0 und so weiter, split2 hat log mit index 1 nicht ... (split zahl - 1 ist index). Also wenn ich die 20 labels für ein log erzeugen will daf man nur die 20 repititions aus dem split benutzen von split mit zahl = log index + 1

\todo{stochastic modelle literatur sagt voting! bei selbe daten können verscheidene ergebnisse rauskommen. wissenschaftlicher begründen wieso ich voting based mache. more reliable and realistic etc. literatuir sagt das ist gut bei stochastischen modellen etc}

\todo{wenn ich trainiere nochmal für die 4 sytsme einfach nochmal acc aufschreibenb}

\todo{kurz erwähnen dass es offline test ist: - real world sacenario 20 modelle ohne splits, offline test leace one out, online test future work (alle data 20 repitions)}

The accuracies shown in section \todo{ref} are not representitive of how the models would perform in real life scenarios. Since the accuracy is the mean accuracy of 20 repititions for each split there is no single modeel that produces that accuracy. For using the modles in real life scenarios a voting based system is deployed. It consists of multple models classifying the input data and then voting for the final classification. The accurcy of such a system more accurately describes the real world performance. Therefore a voting based sytsem is created each for the best cnns and ratios of simulated to real data for each number of step. As mentioned in section \todo{ref} the 1d cnn creates the best accuracy for 5 and 10 rounds while the 2d cnn creates the best accuracies for 15 and 20 rounds. Hence, in total 4 voting based systems are created, one for each of the 4 number of rounds. \todo{besser ref zu einer tabl machen wo die drin stehen} Each of the 20 repititions of a split is tested as before, only with the two real games (one no obstacle and one glare) that were not included in the training. However instead of direclty calculating the accuracy of each repitition of that split, the output labels are saved for all repitions and used to perform a voting for the final label. Meaning that if for instance 15 out of 20 repitions classyfied the game as a glare effect game, while the other 5 classified it as a no obstacle game, the final classification will be that of a glare effect game. This is done for the two test games. Using the final labels created by the voting, the accuracy is calculated. In the example above, if assumed that both final labels would be correct, the accuracy of that split would be 100\%. This procedure is repeated for each of the 20 splits and the accuracies of the splits are averaged. 

It should be noted that voting based systems do not neccesarily have a better accuracy than the average accuracy of the model. To explain this an examplary voting of 20 models will be used, from which 11 classified the game as no obstacle game and 9 as glare effcet game. On the one hand, assuming that the majority of models classifies the game correctly, the result of the 9 wrong classification is ignored. The final predition of the voting will be correct, resulting in a accury of 100\% for that classification in that split. When calculating the average over all splits this will increase the average accuracy. On the other hand, the opposite is equally possible. If assumed that the majority of models in the example classiefies the game wrong, the result of the 9 correct classifications is ignored. The final prediction of the voting will be wrong, resulting in an accuracy of 0\% for that classification in that split. When calculating the average over all splits this will decrease the average accuracy. This example shows that a voting based system can either perform better or worse than the average accuracy of all models. A key factor that influences the outcome is the way the correct votes are distributed acroos the splits. A voting based systems highly profits from low fluctuation in the voting distribution between the models. If the voting in the majority of splits has similar results, such that for instance around 15 models vote correct and 5 vote wrong, the accuracy of those splits will all be 100\% and the average accuracy of the voting will be higher than the average over all models without voting. But if in for instance in the first split 20 models vote correct and 0 incorrect, while in the second split 9 vote correct and 11 incorrect, the overall performance of the voting based system suffers. Instead it would be better if in the example above, in the first split 15 vote correct and 5 incorrect and in the second split 14 vote correct and 6 incorrect, resulting in the accuracy of both split being 100\%. In total in both explained distributions, 29 models vote correct and 11 incorrect, but the performance of the voting based system that has less fluctuation in the distribution performs massively better. 




.. table of accuracies of the 4 voting based systems ...

table with number of overruled correct and false classifications for the four sytsems 



- hyper parameters and topology are not optimized. 
- große schwanukng in den daten
- grund für minimal schelchtere ergebnisse 
- 1d cnn hat durch voting schlechtere -> schwankungen sind groß der modelle
gucken ob es bei 2 d auch so ist und vergleichen 

During training and creation topology and hyper paarameters are best practice confog and not optimized for each model. This is just a offline test, and before production use optimization should be done. Furthermnore for production the inetad of the 20 split and 400 models, only 20 models are trained on all data. it could be also tested to increase the number of repitions as this might increase the performance of the voting. 

It would be possible to use these four systems during a game. Depending on the number of step a differet system is used. 